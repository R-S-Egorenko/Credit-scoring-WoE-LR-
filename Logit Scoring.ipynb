{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc310488-d3e2-448e-89a5-0fa5fc9eb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Last upd: 27.10.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2fb39-f3cb-4344-864c-9d18af993779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QN - вопросы\n",
    "# rwrk - переделать/доработать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676de22e-bc3f-4b99-ae6f-77656ce79ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235c358f-8744-467f-a364-52b890204d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cкорее всего полвина не нужна, но уже не могу вспомнть какие нужны, а какие нет\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import openpyxl\n",
    "\n",
    "# import shutil\n",
    "# import re\n",
    "# import random\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import pickle\n",
    "\n",
    "# from sklearn.utils import shuffle\n",
    "# import mlxtend\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "# import scipy.stats as stats\n",
    "# from sklearn import metrics\n",
    "# from sklearn.metrics import roc_auc_score, f1_score, log_loss, classification_report, confusion_matrix, roc_curve, auc\n",
    "# import functools\n",
    "# from itertools import combinations\n",
    "# from itertools import combinations_with_replacement\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import pandas.core.algorithms as algos\n",
    "# from pandas import Series\n",
    "# import traceback\n",
    "# import string\n",
    "# from ast import literal_eval\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import statsmodels.api as sm\n",
    "# import statsmodels.formula.api as sm\n",
    "# import pylab as pl\n",
    "# import matplotlib.backends.backend_pdf\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "# import seaborn as sns\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c418c7e-144f-4d73-805b-f3c8c01f4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b6add-5046-4b8c-be2a-c2069819c44d",
   "metadata": {},
   "source": [
    "#### Фильтр предупреждений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f711c-7f11-44ad-bd79-6d91791b3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5292c2-518d-4af0-8c5a-9a4e21c0e490",
   "metadata": {},
   "source": [
    "# Функции (позже упаковать в библиотеки/пакеты)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4cac8f-a226-485c-8010-bb1f2f4d19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "from datetime import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde55d08-fd43-4cff-b09d-eaa6a0b33b66",
   "metadata": {},
   "source": [
    "## Разное"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c529e-56d0-4a5d-9cd5-98f01c31b13d",
   "metadata": {},
   "source": [
    "### Замена +/- бесокнечности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c4b62-5ad2-4678-a810-76b2ca51400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "def inf_replacer(df,\n",
    "                 x,\n",
    "                 n_min_max):\n",
    "    try:\n",
    "        p_replace = np.nanmax(df[x][df[x] != np.inf])*n_min_max\n",
    "        df[x] = df[x].replace(np.inf, p_replace)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        n_replace = np.nanmin(df[x][df[x] != -np.inf])*n_min_max\n",
    "        df[x] = df[x].replace(-np.inf, n_replace)\n",
    "    except:\n",
    "        pass\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb91c76-b868-4ec3-87cb-f7452d19c059",
   "metadata": {},
   "source": [
    "## Функции для получения различных метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5430c01-7175-4773-adcf-cd05e5dc77fc",
   "metadata": {},
   "source": [
    "### PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a3390-a9b1-466c-b5af-cd92966ad257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class psi_():\n",
    "    def fit(self,\n",
    "            dev,\n",
    "            val,\n",
    "            feature,\n",
    "            sample_wieght=None):\n",
    "        self.feature = feature\n",
    "        self.dev = dev\n",
    "        self.val = val\n",
    "        self.sample_wieght = sample_wieght  \n",
    "        self.psi = pd.DataFrame()\n",
    "        \n",
    "        if sample_weight is not None:\n",
    "            self.psi['dev_bin_size'] = self.dev.groupby('bin_index_'+self.feature)['sample_weight'].sum()\n",
    "        else:\n",
    "            self.psi['dev_bin_size'] = self.dev.groupby('bin_index_'+self.feature).size() / sum(self.dev.groupby('bin_index_'+self.feature).size())    \n",
    "        \n",
    "        if sample_weight is not None:\n",
    "            self.psi['val_bin_size'] = self.val.groupby('bin_index_'+self.feature)['sample_weight'].sum() / sum(self.val.groupby('bin_index_'+self.feature)['sample_weight'].sum())\n",
    "        else:\n",
    "            self.psi['val_bin_size'] = self.val.groupby('bin_index_'+self.feature).size() / sum(self.val.groupby('bin_index_'+self.feature).size())\n",
    "        \n",
    "        # Для исключения деления на 0\n",
    "        self.psi['dev_bin_size'] = np.where(self.psi['dev_bin_size']==0, \n",
    "                                              1e-6,\n",
    "                                              self.psi['dev_bin_size'])\n",
    "        self.psi['val_bin_size'] = np.where(self.psi['val_bin_size']==0, \n",
    "                                            1e-6, \n",
    "                                            self.psi['val_bin_size'])\n",
    "        self.psi['dev_bin_size'] = self.psi['dev_bin_size'].fillna(1e-6)\n",
    "        self.psi['val_bin_size'] = self.psi['val_bin_size'].fillna(1e-6)\n",
    "        \n",
    "        self.psi['PSI'] = (self.psi['dev_bin_size'] - self.psi['val_bin_size']) * (np.log(self.psi['dev_bin_size'] / self.psi['val_bin_size']))\n",
    "        self.psi_val = self.psi['PSI'].sum()\n",
    "        self.psi.loc['Total'] = self.psi.sum()\n",
    "        self.psi['Feature'] = self.feature\n",
    "        self.psi = self.psi[['Feature','dev_bin_size','val_bin_size','PSI']]\n",
    "        self.psi.index.names = ['bin_index']\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def get_table(self):\n",
    "        return self.psi\n",
    "    def get_psi(self):\n",
    "        return self.psi_val\n",
    "    def plot(self,\n",
    "             show=False,\n",
    "             save = None):\n",
    "        self.psi = self.psi.loc[self.psi.index!='Total']\n",
    "        fig, ax = plt.subplots(figsize=(15, 8))  # Adjust the chart size here\n",
    "        index = np.arange(len(self.psi))\n",
    "        bar_width = 0.35\n",
    "        dev_bars = ax.bar(index, \n",
    "                          self.psi['dev_bin_size'], \n",
    "                          bar_width, \n",
    "                          label='Development sample')\n",
    "        val_bars = ax.bar(index + bar_width, \n",
    "                          self.psi['val_bin_size'], \n",
    "                          bar_width, \n",
    "                          label='Validation sample')\n",
    "        ax.set_xlabel('Bins')\n",
    "        ax.set_ylabel('Percentage')\n",
    "        ax.set_title('WoE_'+self.feature+ f' Population Stability Index (PSI): {self.psi_val:.4f}')\n",
    "        ax.set_xticks(index + bar_width / 2)\n",
    "        ax.set_xticklabels(self.psi.index)\n",
    "        ax.legend()\n",
    "        fig.tight_layout()\n",
    "        if save is not None:\n",
    "            save_fig = os.path.join(save, 'PSI WoE_'+f'{self.feature}'+'.png')\n",
    "            plt.savefig(save_fig)\n",
    "        else:\n",
    "            pass\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a713e17-ee71-403d-988c-d32e5b3544cd",
   "metadata": {},
   "source": [
    "### Стабильность DR по бинам во времени (по годам) на основе изменения рангов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d70a74-8b78-4d98-8ac7-add237fa4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import datetime as dt\n",
    "# from datetime import date\n",
    "# from datetime import time\n",
    "\n",
    "\n",
    "def rank_stability_indexs(df,\n",
    "                          feature,\n",
    "                          freq ='y'): # 'y'/'yq'\n",
    "    df['y'] = df['REP_DATE'].astype('datetime64[ns]').dt.year.astype('string') \n",
    "    df['yq'] = df['REP_DATE'].astype('datetime64[ns]').dt.year.astype('string')+'_Q'+df['REP_DATE'].astype('datetime64[ns]').dt.quarter.astype('string')\n",
    " \n",
    "    dev_ranks = df.groupby('bin_index_'+feature)['target'].mean().rank().astype('Int64')\n",
    "    dev_clean_ranks = df.loc[~df['bin_index_'+feature].isin(['Other','Missing','Special'])].groupby('bin_index_'+feature)['target'].mean().rank().astype('Int64')\n",
    "    # Общая стабильность\n",
    "    dr_stbl = pd.DataFrame()\n",
    "    dr_stbl['bin_size'] = df.groupby(['bin_index_'+feature, freq])['target'].mean()\n",
    "    dr_stbl = dr_stbl.unstack().rank().astype('Int64')\n",
    "\n",
    "    dr_stbl_diff = dr_stbl.copy(deep=True)\n",
    "    for i in dr_stbl.columns:\n",
    "        dr_stbl_diff[i] = abs(dr_stbl_diff[i].sub(dev_ranks.to_numpy(), axis=0))\n",
    "    rank_stability = round(1 - dr_stbl_diff.sum().sum()/dr_stbl_diff.size,2)\n",
    "\n",
    "    clean_dr_stbl = dr_stbl.loc[~dr_stbl.index.isin(['Other','Missing','Special'])].rank().astype('Int64')\n",
    "    clean_dr_stbl_diff = clean_dr_stbl.copy(deep=True)\n",
    "    for i in clean_dr_stbl_diff.columns:\n",
    "        clean_dr_stbl_diff[i] = abs(clean_dr_stbl_diff[i].sub(dev_clean_ranks.to_numpy(), axis=0))\n",
    "    clean_rank_stability = round(1 - clean_dr_stbl_diff.sum().sum()/clean_dr_stbl_diff.size,2)\n",
    "    rank_stab_tab = pd.DataFrame([[feature,\n",
    "                                    rank_stability,\n",
    "                                    clean_rank_stability]],\n",
    "                                 columns = ('feature',\n",
    "                                             'inner_rank_stability',\n",
    "                                             'inner_clean_rank_stability')).set_index('feature')\n",
    "\n",
    "    \n",
    "    return rank_stab_tab\n",
    "\n",
    "# Пример вызова функции\n",
    "# rank_stab_tab = rank_stability_indexs(df, feature = 'bki_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed78ccd-bc6e-4ed2-9e46-73c2f6f1ac98",
   "metadata": {},
   "source": [
    "### Ранговая корреляция Спирмена (сравнение разработки и OOT выборки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdae95-0022-4a87-98e1-46ce35e51df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "\n",
    "\n",
    "def spearmanr_stability(dev, \n",
    "                        val, \n",
    "                        feature,\n",
    "                        target):\n",
    "    dev_ranks = dev.groupby('bin_index_'+feature)[target].mean().rank()\n",
    "    val_ranks = val.groupby('bin_index_'+feature)[target].mean().rank()\n",
    "    \n",
    "    dev_clean_ranks = dev.loc[~dev['bin_index_'+feature].isin(['Other','Missing','Special'])].groupby('bin_index_'+feature)[target].mean().rank()\n",
    "    val_clean_ranks = val.loc[~val['bin_index_'+feature].isin(['Other','Missing','Special'])].groupby('bin_index_'+feature)[target].mean().rank()\n",
    "\n",
    "    statistic, pvalue = stats.spearmanr(a=dev_clean_ranks, \n",
    "                                        b=val_clean_ranks, \n",
    "                                        axis=0, \n",
    "                                        nan_policy='propagate', \n",
    "                                        alternative='two-sided')\n",
    "    \n",
    "    statistic_clean, clean_pvalue = stats.spearmanr(a=dev_ranks, \n",
    "                                                  b=val_ranks, \n",
    "                                                  axis=0, \n",
    "                                                  nan_policy='propagate', \n",
    "                                                  alternative='two-sided')\n",
    "    spearman_rs = pd.DataFrame([[feature,\n",
    "                             round(statistic,5),\n",
    "                             round(statistic_clean,5)]],\n",
    "                           columns = ('feature',\n",
    "                                      'Spearman_r_(dev/oot)',\n",
    "                                      'clean_Spearman_r_(dev/oot)')).set_index('feature')\n",
    "    return spearman_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347abbc-fd57-4fc8-8684-b172dc83e1d1",
   "metadata": {},
   "source": [
    "## Функции биннинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2aba03-aab1-4f52-84f3-688198ce25f3",
   "metadata": {},
   "source": [
    "### Вспомогательные функции для биннинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f92a8a-393d-4b65-bd99-e208b5e6bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import tree\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "sklearn.set_config(enable_metadata_routing=True)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433e572-a3a1-4eff-8616-dc217070be3a",
   "metadata": {},
   "source": [
    "#### Пре-процессинг для биннинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cc285-43d9-466c-90c4-84599f3691da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лист фреймов данных для биннинга\n",
    "#------------------------------------------------------------------------------------ START\n",
    "def pre_processing(df,\n",
    "                   dtype , # 'categorical/numerical'\n",
    "                   feature,\n",
    "                   target,\n",
    "                   sample_weight = None,\n",
    "                   special_list = [],\n",
    "                   cat_other_cutoff = None\n",
    "                  ):\n",
    "    other_list = []\n",
    "    if (dtype == 'categorical') and (cat_other_cutoff is not None):\n",
    "        others_to_missing, other_list = categorical_cutoff(df, \n",
    "                                                           feature, \n",
    "                                                           cat_other_cutoff,\n",
    "                                                           sample_weight)\n",
    "        if others_to_missing:\n",
    "            df[feature] = np.where(df[feature].isin(other_list),\n",
    "                                   np.nan,\n",
    "                                   df[feature])\n",
    "            other_list = []\n",
    "    else:\n",
    "        pass\n",
    "## X, Y пропуски \n",
    "    x_na = df[[feature]].loc[df[feature].isna()]\n",
    "    y_na = df[[target]][df.index.isin(x_na.index)]\n",
    "## X, Y спец-значения \n",
    "    x_special = df[[feature]].loc[df[feature].isin(special_list)]\n",
    "    y_special = df[[target]][df.index.isin(x_special.index)]\n",
    "## X, Y менее cut_off % для категориальных показателей\n",
    "    x_other = df[[feature]].loc[df[feature].isin(other_list)]\n",
    "    y_other = df[[target]][df.index.isin(x_other.index)]\n",
    "## X,Y clean\n",
    "    x_clean = df[[feature]]\\\n",
    "    .loc[~df[feature].isna()]\\\n",
    "    .loc[~df[feature].isin(other_list)]\\\n",
    "    .loc[~df[feature].isin(special_list)]\n",
    "    y_clean = df[[target]][df.index.isin(x_clean.index)]\n",
    "## Sample_weight..  -_clean, -_other, -_special, -_na\n",
    "    if sample_weight is not None:\n",
    "        sw_clean = df[[sample_weight]][df.index.isin(x_clean.index)]\n",
    "        sw_na = df[[sample_weight]][df.index.isin(x_na.index)]\n",
    "        sw_special = df[[sample_weight]][df.index.isin(x_special.index)]\n",
    "        sw_other = df[[sample_weight]][df.index.isin(x_other.index)]\n",
    "    else:\n",
    "        sw_clean = None\n",
    "        sw_na = None\n",
    "        sw_special = None\n",
    "        sw_other = None\n",
    "## frame_list[i] index для образения к объекту\n",
    "    frame_list = [x_clean, # frame_list[0]\n",
    "                  y_clean, # frame_list[1]\n",
    "                  sw_clean, # frame_list[2]\n",
    "                  x_na, # frame_list[3]\n",
    "                  y_na, # frame_list[4] \n",
    "                  sw_na, # frame_list[5]\n",
    "                  x_special, # frame_list[6] \n",
    "                  y_special, # frame_list[7] \n",
    "                  sw_special, # frame_list[8]\n",
    "                  x_other, # frame_list[9]\n",
    "                  y_other, # frame_list[10] \n",
    "                  sw_other] # frame_list[11]    \n",
    "\n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926d2a1-0796-4e9e-9d58-16c0d2f16327",
   "metadata": {},
   "source": [
    "#### Выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54ce22-b05d-438f-8c3f-2442a291ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Работа с выбросами (outlier_detector)\n",
    "#------------------------------------------------------------------------------------ START\n",
    "#------------------------------------------------------------------------------------ start(1)\n",
    "## IQR detector\n",
    "def iqr_filter(x):\n",
    "    sub_x_clean = x.loc[\n",
    "    np.array((x >= (stats.iqr(x)-1.5*x.min())))\\\n",
    "    & np.array((x <= (stats.iqr(x)+1.5*x.max())))\n",
    "    ]\n",
    "    return sub_x_clean\n",
    "#------------------------------------------------------------------------------------ end(1)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(2)\n",
    "## KNN detector\n",
    "def knn_filter(x,\n",
    "               n_neighbors = 5):\n",
    "    knn = NearestNeighbors(n_neighbors = n_neighbors).fit(x)\n",
    "    mean_distances = pd.DataFrame(knn.kneighbors(x)[0]).mean(axis=1)\n",
    "    threshold = mean_distances.quantile(0.95)\n",
    "    clean_indxs = np.where(mean_distances <= threshold)\n",
    "    sub_x_clean = x.iloc[clean_indxs]\n",
    "    return sub_x_clean\n",
    "#------------------------------------------------------------------------------------ end(2)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(3)\n",
    "##  Z_score_modified detector\n",
    "def m_z_score_filter(x,\n",
    "                     threshold=3.5):\n",
    "##### Беру k=0,6745, применямый для полу-нормальных распределений, \n",
    "##### что позволит использовать MAD, как аналог стандартного отклонения\n",
    "##### https://en.wikipedia.org/wiki/Median_absolute_deviation\n",
    "    sub_x_clean =  x.loc[\n",
    "    np.array((abs(0.6745 * (x - x.median()) / (np.median(np.abs(x - x.median()))))) < threshold)\n",
    "    ]\n",
    "    return sub_x_clean\n",
    "#------------------------------------------------------------------------------------ end(3)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(4)\n",
    "## Z_score detector\n",
    "def z_score_filter(x,\n",
    "                   threshold=3):\n",
    "    sub_x_clean = x.loc[np.array(stats.zscore(x, ddof = 1)) < threshold]\n",
    "    return sub_x_clean\n",
    "#------------------------------------------------------------------------------------ END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ee170-1308-410a-875b-9ac1bbf5ca99",
   "metadata": {},
   "source": [
    "#### Проверка направления тренда "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be990c-cdb1-420d-bf21-5c0ddeb1bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка направления связи\n",
    "#------------------------------------------------------------------------------------ START\n",
    "def trend_check(x,\n",
    "                y, \n",
    "                sample_weight=None,\n",
    "                n_bins=20):\n",
    "    if sample_weight is not None:\n",
    "        sample_weight = sample_weight\n",
    "    else:\n",
    "        sample_weight = None\n",
    "## Дискретизация данных\n",
    "    kbd = KBinsDiscretizer(n_bins = n_bins,\n",
    "                           strategy='quantile', # uniform\n",
    "                           random_state = seed,\n",
    "                           subsample = None,\n",
    "                           encode = 'ordinal'\n",
    "                          )\n",
    "    kbd.fit(x, \n",
    "            sample_weight = sample_weight).set_fit_request(sample_weight=True)    \n",
    "    mono_check = pd.DataFrame({'x':pd.Series(x.ravel()),\n",
    "                               'target':pd.Series(y),\n",
    "                               'sample_weight':pd.Series(sample_weight)},\n",
    "                             )\n",
    "    mono_check['bin_index'] = kbd.transform(x).astype('int64')\n",
    "    mono_check_ = pd.DataFrame()\n",
    "    if sample_weight is not None:\n",
    "        mono_check_['sample_weight'] = mono_check.groupby('bin_index')['sample_weight'].sum()\n",
    "    else:\n",
    "        pass\n",
    "    mono_check_['target'] = mono_check.groupby('bin_index')['target'].mean()\n",
    "    X = mono_check_.index.values\n",
    "    Y = mono_check_['target'].values\n",
    "    if sample_weight is not None:\n",
    "        sample_weight = mono_check_['sample_weight'].values\n",
    "    else:\n",
    "        sample_weight = None\n",
    "### Полином 1 степени (линейная регрессия) для определения наклона лнии тренда\n",
    "    lr_coef = np.polyfit(X, \n",
    "                         Y,\n",
    "                         w=sample_weight,\n",
    "                         deg=1)[0]\n",
    "### Определение monotonic_cst исходя из коэффициента наклона уравнения линейной регрессии\n",
    "    if lr_coef > 0:\n",
    "        monotonic_cst = 1 # Increase\n",
    "        lr_sense = 'Increase'\n",
    "    elif lr_coef < 0:\n",
    "        monotonic_cst = -1 # Decrease\n",
    "        lr_sense = 'Decrease'\n",
    "    elif lr_coef == 0:\n",
    "        monotonic_cst = 0 # None\n",
    "        lr_sense = 'None'\n",
    "\n",
    "    return lr_sense, monotonic_cst\n",
    "#------------------------------------------------------------------------------------ END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125f906-7d14-4e8b-b112-f1719db3d06f",
   "metadata": {},
   "source": [
    "#### \"Others\" - выделение редких наблюдений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb667b-dd8e-434f-9bbf-fe356e224ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделение редко-встречающихся (менее, чем в x% случаев) категорий в отдельный бин\n",
    "#------------------------------------------------------------------------------------ START\n",
    "def categorical_cutoff(df, \n",
    "                       feature,\n",
    "                       cat_other_cutoff=None, \n",
    "                       sample_weight=None):\n",
    "    if sample_weight is None:\n",
    "        x = df[feature]\n",
    "        cutoff_count = np.ceil(cat_other_cutoff * len(x))\n",
    "        cat_tab = pd.Series(x).value_counts()\n",
    "        other_list = cat_tab[cat_tab < cutoff_count].index.values\n",
    "        mask_others = pd.Series(x).isin(other_list).values\n",
    "        min_other_size = np.ceil(len(x)*0.01)\n",
    "        other_size = len(x[x.isin(other_list)])\n",
    "        others_to_missing = min_other_size >= other_size\n",
    "    else:\n",
    "        x = df[[feature,sample_weight]]\n",
    "        cutoff_weight = cat_other_cutoff * sum(x[sample_weight])\n",
    "        # pd.concat([x,df[sample_weight]], ignore_index=False, axis = 1)\n",
    "        cat_tab = x.groupby([feature])[sample_weight].agg('sum')\n",
    "        other_list = cat_tab[cat_tab < cutoff_weight].index.values\n",
    "        mask_others = pd.Series(x[feature]).isin(other_list).values\n",
    "        min_other_size = x[sample_weight].sum()*0.01\n",
    "        other_size = x[x.isin(other_list)][sample_weight].sum()\n",
    "        others_to_missing = min_other_size >= other_size \n",
    "    if np.count_nonzero(~mask_others) == 0:\n",
    "            raise ValueError(str('Все значения ' + feature + ' попали в категорию Others'))\n",
    "    return others_to_missing, other_list\n",
    "\n",
    "# # Пример вызова функции \n",
    "# other_list= categorical_cutoff(df = df_cat, \n",
    "#                                 feature='reg_region', \n",
    "#                                 cat_other_cutoff = 0.01,\n",
    "#                                 sample_weight = 'sample_weight')\n",
    "#------------------------------------------------------------------------------------ END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d4ac9-a796-421d-8da5-623695e7339b",
   "metadata": {},
   "source": [
    "### Биннинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ed123-762a-47d4-8a3d-e175225e0c0f",
   "metadata": {},
   "source": [
    "#### Биннинг категориальных (дискретных) показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f0fcf0-36b8-405b-a1a0-f7139ee7d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------ START\n",
    "class categorical_binning:\n",
    "#------------------------------------------------------------------------------------ start(1)\n",
    "## Инициация биннинга, задать парамтеры для фунции\n",
    "    def __init__(self,\n",
    "                 target_type, # 'binary'/'continuous'\n",
    "                 n_bins, # Количество бакетов в биннинге\n",
    "                 seed,\n",
    "                 min_bin_size, # Минимальный размер бакета,\n",
    "                 cat_other_cutoff = None,\n",
    "                 woe_calc_method = None # 'sum_surrogate'/'mean_surrogate'\n",
    "                 ):\n",
    "        self.seed = seed\n",
    "        self.target_type = target_type\n",
    "        self.n_bins = n_bins\n",
    "        self.min_bin_size = min_bin_size\n",
    "        self.cat_other_cutoff = cat_other_cutoff\n",
    "        self.woe_calc_method = woe_calc_method  \n",
    "#------------------------------------------------------------------------------------ end(1)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(2)\n",
    "## К инициированному объекту применяется .fit() с заданными параметрами\n",
    "    def fit(self, \n",
    "            df,\n",
    "            feature,\n",
    "            target,\n",
    "            special_list =[],\n",
    "            sample_weight = None,\n",
    "            dtype = 'categorical'):\n",
    "### Подготовка вводных данных для обучения функции биннинга  \n",
    "        self.frame_list = pre_processing(df,\n",
    "                                         dtype,\n",
    "                                         feature,\n",
    "                                         target,\n",
    "                                         sample_weight,\n",
    "                                         special_list,\n",
    "                                         self.cat_other_cutoff)\n",
    "        self.feature = feature\n",
    "        self.sample_weight = sample_weight\n",
    "        self.target = target\n",
    "        #------------------------------------------------------------\n",
    "        # Индексы объектов в frame_list\n",
    "        # x_clean = frame_list[0]\n",
    "        # y_clean = frame_list[1]\n",
    "        # sw_clean = frame_list[2]\n",
    "        # x_na = frame_list[3]\n",
    "        # y_na = frame_list[4] \n",
    "        # sw_na = frame_list[5]\n",
    "        # x_special = frame_list[6] \n",
    "        # y_special = frame_list[7] \n",
    "        # sw_special = frame_list[8]\n",
    "        # x_other = frame_list[9]\n",
    "        # y_other = frame_list[10] \n",
    "        # sw_other = frame_list[11]\n",
    "        #------------------------------------------------------------\n",
    "\n",
    "#### Alphabetical encoding\n",
    "        # encoder = preprocessing.LabelEncoder()\n",
    "        # encoder.fit(self.frame_list[0].values.ravel())\n",
    "        # X = encoder.transform(self.frame_list[0].values.ravel()).reshape(-1, 1)\n",
    "####----------------------------------------------------------------- encoding end\n",
    "#### Target mean encoding\n",
    "        encoder = preprocessing.TargetEncoder(random_state = self.seed,\n",
    "                                              target_type = self.target_type)\n",
    "        encoder.fit(self.frame_list[0].values.reshape(-1, 1),\n",
    "                    self.frame_list[1].values.ravel())\n",
    "        X = encoder.transform(self.frame_list[0].values.reshape(-1, 1))\n",
    "        encoding_map = dict(zip(X.ravel(),\n",
    "                                self.frame_list[0].values.ravel()\n",
    "                               )\n",
    "                           )\n",
    "####----------------------------------------------------------------- encoding end\n",
    "        \n",
    "        Y = self.frame_list[1].values.ravel()\n",
    "        if self.sample_weight is not None:\n",
    "            S_W = self.frame_list[2].values.ravel()\n",
    "        else:\n",
    "            S_W = None\n",
    "### Бинарный таргет target_type == 'binary'\n",
    "### CART - Decision Tree Classifier \n",
    "        if self.target_type == 'binary':\n",
    "            cart_kwargs = {'min_samples_leaf' : self.min_bin_size,\n",
    "                           'max_leaf_nodes' : self.n_bins,\n",
    "                           'random_state' : self.seed,\n",
    "                           'criterion' : 'gini'}    \n",
    "            cart_model = DecisionTreeClassifier(**cart_kwargs)\n",
    "            fit_args = {'X':X,\n",
    "                        'y':Y,\n",
    "                        'sample_weight':S_W}\n",
    "            cart_model.fit(**fit_args)     \n",
    "### Бинарный таргет target_type == 'continuous'\n",
    "### CART - Decision Tree Regressor\n",
    "        elif self.target_type == 'continuous':\n",
    "            cart_kwargs = {'min_samples_leaf' : self.min_bin_size,\n",
    "                           'max_leaf_nodes' : self.n_bins,\n",
    "                           'random_state' : self.seed,\n",
    "#### MAE более устойчив к выбросам, чем MSE, поэтому для качественных признаков выбран MSE, а для количественных MAE\n",
    "                           'criterion' : 'friedman_mse'}\n",
    "            cart_model = DecisionTreeRegressor(**cart_kwargs)\n",
    "            fit_args = {'X':X,\n",
    "                        'y':Y,\n",
    "                        'sample_weight':S_W}\n",
    "            cart_model.fit(**fit_args)\n",
    "        # return self\n",
    "### Построение внутренней таблицы - self.tab для расчета woe\n",
    "#### Основная таблица tab\n",
    "\n",
    "#### Alphabetical reverse encoding\n",
    "        # data = {self.feature : encoder.inverse_transform(X.ravel())}\n",
    "####----------------------------------------------------------------- reverse encoding end\n",
    "#### Target mean reverse encoding\n",
    "        data = {self.feature : pd.Series(X.ravel()).map(encoding_map)}\n",
    "####----------------------------------------------------------------- reverse encoding end\n",
    "        data.update({'bin_index' : cart_model.apply(X, check_input=True),\n",
    "                     'target' : self.frame_list[1].values.ravel()})\n",
    "        if self.sample_weight is not None:\n",
    "            data.update({'sample_weight' : self.frame_list[2].values.ravel()})\n",
    "        else:\n",
    "            pass\n",
    "        self.tab = pd.DataFrame(data)       \n",
    "        if self.sample_weight is not None:\n",
    "            index_map = (self.tab.loc[self.tab['target']==1].groupby('bin_index')['sample_weight'].sum()/ \\\n",
    "            self.tab.groupby('bin_index')['sample_weight'].sum()).reset_index()\n",
    "            index_map['bin_true'] = stats.rankdata(index_map['sample_weight']).astype('int64')\n",
    "            index_map = dict(zip(index_map['bin_index'],\n",
    "                                 index_map['bin_true']))\n",
    "            self.tab['bin_index'] = self.tab['bin_index'].map(index_map)\n",
    "        else:\n",
    "            index_map = (self.tab.loc[self.tab['target']==1].groupby('bin_index').size()/ \\\n",
    "            self.tab.groupby('bin_index').size()).reset_index()\n",
    "            index_map['bin_true'] = stats.rankdata(index_map[0]).astype('int64')\n",
    "            index_map = dict(zip(index_map['bin_index'],\n",
    "                                 index_map['bin_true']))\n",
    "            self.tab['bin_index'] = self.tab['bin_index'].map(index_map)\n",
    "#### Дополнительные таблицы для tab \n",
    "##### Таблица с пропусками\n",
    "        data = {self.feature:self.frame_list[3].values.ravel(),\n",
    "                'bin_index':'Missing',\n",
    "                'target':self.frame_list[4].values.ravel()}\n",
    "        if self.sample_weight is not None:\n",
    "            data.update({'sample_weight':self.frame_list[5].values.ravel()})\n",
    "        else:\n",
    "            pass\n",
    "        na_tab = pd.DataFrame(data)\n",
    "##### Таблица с специальными значениями\n",
    "        data = {self.feature:self.frame_list[6].values.ravel(),\n",
    "                'bin_index':'Special',\n",
    "                'target':self.frame_list[7].values.ravel()}\n",
    "        if self.sample_weight is not None:\n",
    "            data.update({'sample_weight':self.frame_list[8].values.ravel()})\n",
    "        else:\n",
    "            pass\n",
    "        special_tab = pd.DataFrame(data)\n",
    "##### Таблица с Прочими (менее i%)\n",
    "        data = {self.feature:self.frame_list[9].values.ravel(),\n",
    "                'bin_index':'Other',\n",
    "                'target':self.frame_list[10].values.ravel()}\n",
    "        if self.sample_weight is not None:\n",
    "            data.update({'sample_weight':self.frame_list[11].values.ravel()})\n",
    "        else:\n",
    "            pass\n",
    "        other_tab = pd.DataFrame(data)\n",
    "#### Создание общей таблицы с дополнительными значениями\n",
    "        tab_add = pd.concat([na_tab,\n",
    "                             special_tab,\n",
    "                             other_tab]).reset_index(drop=True)\n",
    "\n",
    "##### Снижение размера выходных pickle-файлов        \n",
    "        del na_tab, special_tab, other_tab\n",
    "#### Индексы для таблицы WoE       \n",
    "        self.indxs = ['Other','Special','Missing']\n",
    "        self.indxs = sorted((set(self.indxs))&\\\n",
    "                       set(list(tab_add['bin_index'].unique())), key = self.indxs.index)\n",
    "        self.indxs = list(np.sort(self.tab['bin_index'].unique()))+self.indxs   \n",
    "        self.tab = pd.concat([self.tab,\n",
    "                              tab_add]).reset_index(drop=True)\n",
    "        del tab_add\n",
    "### Создание объекта splits - словаря полученных в результате автоматического разбиения классов, для трансформации\n",
    "        self.user_map = None\n",
    "        self.splits = {}\n",
    "        self.splits = self.tab.groupby('bin_index')[self.feature].unique().to_dict()\n",
    "        self.splits = dict(zip(\n",
    "            self.splits.keys(),\n",
    "            map(tuple,self.splits.values())\n",
    "        ))\n",
    "        self.auto_map = {}\n",
    "        for key, values in self.splits.items():\n",
    "            for item in values:\n",
    "                self.auto_map[item] = key    \n",
    "        return self\n",
    "#------------------------------------------------------------------------------------ end(2)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(3)\n",
    "## Создание объекта splits - словаря полученных в результате автоматического разбиения классов\n",
    "#### Можно сделать через @property, но работает и так\n",
    "    def get_auto_splits(self):\n",
    "        return self.splits\n",
    "#------------------------------------------------------------------------------------ end(3)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(4)\n",
    "## Пользовательская (ручная) коррекция полученного разбиения на классы\n",
    "    def user_splits(self,\n",
    "                    user_splits=None):\n",
    "        if user_splits is not None:\n",
    "#### user_splits при необходимости коррекции разбиения задается, как dict-like объект\n",
    "#### user_splits = {1:('a','b','c'), 2:('d','e','f'),...,'Special':('...'),...}\n",
    "            self.user_map = {}\n",
    "            for key, values in user_splits.items():\n",
    "                for item in values:\n",
    "                    self.user_map[item] = key\n",
    "            self.tab['bin_index'] = self.tab[self.feature].map(self.user_map)\n",
    "        else:\n",
    "            pass\n",
    "        return self\n",
    "#------------------------------------------------------------------------------------ end(4)\n",
    "    \n",
    "#------------------------------------------------------------------------------------ start(5)\n",
    "## Расчет WoE, IV и получение итоговых таблиц tab и woe\n",
    "    def calculate_woe(self):\n",
    "        self.woe = pd.DataFrame()\n",
    "### Расчет для бинарных показателей\n",
    "        if self.target_type == 'binary':\n",
    "            if self.sample_weight is not None:\n",
    "                self.woe['bin_size'] = self.tab.groupby('bin_index')['sample_weight'].sum()\n",
    "                self.woe['event'] = self.tab.loc[self.tab['target']==1].groupby('bin_index')['sample_weight'].sum()\n",
    "            else:\n",
    "                self.woe['bin_size'] = self.tab.groupby('bin_index').size()\n",
    "                self.woe['event'] = self.tab.loc[self.tab['target']==1].groupby('bin_index').size()\n",
    "            self.woe['event'] = self.woe['event'].fillna(1e-6) # ВОЗМОЖНОЕ МЕСТО ОШИБКИ\n",
    "            self.woe['non_event'] = self.woe['bin_size'] - self.woe['event']\n",
    "            self.woe['event_rate'] = self.woe['event'] / self.woe['bin_size'] \n",
    "            self.woe['dstr_event'] = self.woe['event'] / sum(self.woe['event'])\n",
    "            self.woe['dstr_non_event'] = self.woe['non_event'] / sum(self.woe['non_event'])\n",
    "            self.woe['WoE'] = np.log(self.woe['dstr_non_event'] / self.woe['dstr_event'])\n",
    "            self.woe['IV'] = sum(abs((self.woe['dstr_non_event'] - self.woe['dstr_event']) * self.woe['WoE']))\n",
    "            self.woe['feature'] = self.feature\n",
    "            self.woe['values_in_bin'] = self.tab.groupby('bin_index')[self.feature].unique()\n",
    "            self.woe = self.woe[['feature',\n",
    "                       'bin_size',\n",
    "                       'event',\n",
    "                       'event_rate',\n",
    "                       'WoE',\n",
    "                       'IV',\n",
    "                       'values_in_bin']]\n",
    "            self.woe = self.woe.reindex(self.indxs)\n",
    "### Расчет для непрерывных показателей\n",
    "        elif self.target_type == 'continuous':\n",
    "##### QN - Взвешивание целевой переменной (не уверен надо ли это)\n",
    "            if self.sample_weight is not None:\n",
    "                self.tab['target_weighted']=self.tab['target']*self.tab['sample_weight']  \n",
    "#### 'sum_surrogate'/'mean_surrogate'\n",
    "            if self.woe_calc_method == 'mean_surrogate':\n",
    "### Описание: https://gnpalencia.org/optbinning/tutorials/tutorial_continuous.html\n",
    "                self.woe = pd.DataFrame()\n",
    "                if self.sample_weight is not None:\n",
    "                    self.woe['bin_size'] = self.tab.groupby('bin_index')['sample_weight'].sum()\n",
    "                    self.woe['bin_mean'] = self.tab.groupby('bin_index')['target_weighted'].mean()\n",
    "                    self.woe['mean_target'] = self.tab['target_weighted'].mean()\n",
    "                else:\n",
    "                    self.woe['bin_size'] = self.tab.groupby('bin_index').size()\n",
    "                    self.woe['bin_mean'] = self.tab.groupby('bin_index')['target'].mean()\n",
    "                    self.woe['mean_target'] = self.tab['target'].mean()\n",
    "                self.woe['dstr_obs'] = self.woe['bin_size'] / self.woe['bin_size'].sum()\n",
    "                self.woe['WoE'] = self.woe['bin_mean'] - self.woe['mean_target']\n",
    "                self.woe['IV'] = sum(self.woe['dstr_obs']*abs(self.woe['WoE']))\n",
    "                self.woe['feature'] = self.feature\n",
    "                self.woe['values_in_bin'] = self.tab.groupby('bin_index')[self.feature].unique()\n",
    "                self.woe = self.woe[['feature',\n",
    "                           'bin_size',\n",
    "                           'bin_mean',\n",
    "                           'mean_target',\n",
    "                           'WoE',\n",
    "                           'IV',\n",
    "                           'values_in_bin']]\n",
    "                self.woe = self.woe.reindex(self.indxs)\n",
    "            elif self.woe_calc_method == 'sum_surrogate':\n",
    "#### Опсиание: https://www.listendata.com/2019/08/WOE-IV-Continuous-Dependent.html\n",
    "                self.woe = pd.DataFrame()\n",
    "                if self.sample_weight is not None:\n",
    "                    self.woe['bin_size'] = self.tab.groupby('bin_index')['sample_weight'].sum()\n",
    "                    self.woe['target_sum'] = self.tab.groupby('bin_index')['target_weighted'].sum()\n",
    "                else:\n",
    "                    self.woe['bin_size'] = self.tab.groupby('bin_index').size()    \n",
    "                    self.woe['target_sum'] = self.tab.groupby('bin_index')['target'].sum()\n",
    "                self.woe['dstr_obs'] = self.woe['bin_size'] / self.woe['bin_size'].sum()\n",
    "                self.woe['dstr_target'] = self.woe['target_sum'] / self.woe['target_sum'].sum()  \n",
    "                self.woe['WoE'] = np.log(self.woe['dstr_target'] / self.woe['dstr_obs'])\n",
    "                self.woe['IV'] = abs((( self.woe['dstr_target'] - self.woe['dstr_obs']) * self.woe['WoE'])).sum()\n",
    "                self.woe['feature'] = self.feature\n",
    "                self.woe['values_in_bin'] = self.tab.groupby('bin_index')[self.feature].unique()\n",
    "                self.woe = self.woe[['feature',\n",
    "                           'bin_size',\n",
    "                           'target_sum',\n",
    "                           'WoE',\n",
    "                           'IV',\n",
    "                           'values_in_bin']]\n",
    "                self.woe = self.woe.reindex(self.indxs)\n",
    "            elif self.woe_calc_method is None:\n",
    "                print(\"Задайте параметр woe_calc_method во время инициации функции ('sum_surrogate'/'mean_surrogate')\")\n",
    "        self.woe['WoE'] = np.where(self.woe['event']==1e-6, 0, self.woe['WoE']) # ЕЩЕ ОДНО МЕСТО ВОЗМОЖНОЙ ОШИБКИ\n",
    "        self.woe['WoE'] = np.where(self.woe['event']==0, 0, self.woe['WoE']) # ЕЩЕ ОДНО МЕСТО ВОЗМОЖНОЙ ОШИБКИ\n",
    "##### Снижение размера выходных pickle-файлов\n",
    "        del self.tab\n",
    "        del self.frame_list\n",
    "        return self\n",
    "## Извлечение таблицы WoE\n",
    "    def get_woe_table(self):\n",
    "        return self.woe\n",
    "## WoE трансформация показателей в исходном DataFrame()\n",
    "    def woe_transform(self,\n",
    "                      df,\n",
    "                      drop_bin_index = False): # Заполнить новые значения 'Other' или 'Missing'\n",
    "        if self.user_map is not None:\n",
    "            df['bin_index_'+self.feature] = df[self.feature].map(self.user_map)\n",
    "        else:\n",
    "            df['bin_index_'+self.feature] = df[self.feature].map(self.auto_map)\n",
    "            \n",
    "        if 'Other' not in self.indxs:\n",
    "            df['bin_index_'+self.feature] = df['bin_index_'+self.feature].fillna('Missing')\n",
    "        else:\n",
    "            df['bin_index_'+self.feature] = df['bin_index_'+self.feature].fillna('Other')\n",
    "\n",
    "        df['WoE_'+self.feature]=df['bin_index_'+self.feature].map((self.woe[['WoE']].T.to_dict('records'))[0])\n",
    "        if drop_bin_index:\n",
    "            df = df.drop(columns = ['bin_index_'+self.feature], errors='ignore')\n",
    "        else:\n",
    "            pass\n",
    "        return df\n",
    "#------------------------------------------------------------------------------------ end(5)\n",
    "#------------------------------------------------------------------------------------ END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a9810-6452-4483-9450-848de29b6397",
   "metadata": {},
   "source": [
    "#### Биннинг числовых показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07022d6f-3ca3-4536-86fd-cab872796fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------ START\n",
    "class numerical_binning:\n",
    "#------------------------------------------------------------------------------------ start(1)\n",
    "## Инициация биннинга, задать парамтеры для фунции\n",
    "    def __init__(self,\n",
    "                 target_type, # 'binary'/'continuous'\n",
    "                 n_bins, # Количество бакетов в биннинге\n",
    "                 seed,\n",
    "                 min_bin_size, # Минимальный размер бакета,\n",
    "                 outlier_detector = None, # 'iqr','knn','z_score','z_score_mod'\n",
    "                 n_neighbors = 5, # если выбран метод outlier_detector == 'knn' можно задать \"количество ближайших соседей\"\n",
    "                 woe_calc_method = None # 'sum_surrogate'/'mean_surrogate'\n",
    "                 ):\n",
    "        self.seed = seed\n",
    "        self.target_type = target_type\n",
    "        self.n_bins = n_bins\n",
    "        self.min_bin_size = min_bin_size\n",
    "        self.woe_calc_method = woe_calc_method \n",
    "        self.outlier_detector = outlier_detector\n",
    "        if self.outlier_detector == 'knn':\n",
    "            self.n_neighbors = n_neighbors\n",
    "        else:\n",
    "            pass\n",
    "#------------------------------------------------------------------------------------ end(1)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(2)\n",
    "## К инициированному объекту применяется .fit() с заданными параметрами\n",
    "    def fit(self, \n",
    "            df,\n",
    "            feature,\n",
    "            target,\n",
    "            special_list =[],\n",
    "            sample_weight = None,\n",
    "            dtype = 'numerical'):\n",
    "### Подготовка вводных данных для обучения функции биннинга  \n",
    "        self.frame_list = pre_processing(df,\n",
    "                                         dtype,\n",
    "                                         feature,\n",
    "                                         target,\n",
    "                                         sample_weight,\n",
    "                                         special_list)\n",
    "### Условный тест на дискретность с наложенным ограничением на количество бинов\n",
    "#### Лучше дискретные показатели проводить через категориальный биннинг\n",
    "        if self.frame_list[0].nunique().iloc[0] < self.n_bins:\n",
    "            self.n_bins = self.frame_list[0].nunique().iloc[0]\n",
    "            is_discrete = True\n",
    "        else:\n",
    "            is_discrete = False\n",
    "        if is_discrete:\n",
    "            self.outlier_detector = None\n",
    "        else:\n",
    "            pass\n",
    "        self.special_list = special_list\n",
    "        self.feature = feature\n",
    "        self.sample_weight = sample_weight\n",
    "        self.target = target\n",
    "        #------------------------------------------------------------\n",
    "        # Индексы объектов в frame_list\n",
    "        # x_clean = frame_list[0]\n",
    "        # y_clean = frame_list[1]\n",
    "        # sw_clean = frame_list[2]\n",
    "        # x_na = frame_list[3]\n",
    "        # y_na = frame_list[4] \n",
    "        # sw_na = frame_list[5]\n",
    "        # x_special = frame_list[6] \n",
    "        # y_special = frame_list[7] \n",
    "        # sw_special = frame_list[8]\n",
    "        # x_other = frame_list[9]\n",
    "        # y_other = frame_list[10] \n",
    "        # sw_other = frame_list[11]\n",
    "        #------------------------------------------------------------\n",
    "        if self.outlier_detector is not None:\n",
    "            if self.outlier_detector == 'iqr':\n",
    "                X = iqr_filter(self.frame_list[0])\n",
    "            elif self.outlier_detector == 'knn':\n",
    "                 X = knn_filter(self.frame_list[0], \n",
    "                                n_neighbors = self.n_neighbors)\n",
    "            elif self.outlier_detector == 'z_score':\n",
    "                X = z_score_filter(self.frame_list[0])\n",
    "            elif self.outlier_detector =='z_score_mod':\n",
    "                X = m_z_score_filter(self.frame_list[0])        \n",
    "            Y = self.frame_list[1][self.frame_list[1].index.isin(X.index)].values.ravel()\n",
    "            if self.sample_weight is not None:\n",
    "                S_W = self.frame_list[2][self.frame_list[2].index.isin(X.index)].values.ravel()\n",
    "            else:\n",
    "                S_W = None\n",
    "            X = X.values.ravel().reshape(-1, 1)\n",
    "        else:\n",
    "            X = self.frame_list[0].values.ravel().reshape(-1, 1)\n",
    "            Y = self.frame_list[1].values.ravel()\n",
    "            if self.sample_weight is not None:\n",
    "                S_W = self.frame_list[2].values.ravel()\n",
    "            else:\n",
    "                S_W = None\n",
    "        if is_discrete:\n",
    "            monotonic_cst = 0\n",
    "            self.lr_sense = 'None (discrete feature)'\n",
    "        else:\n",
    "            self.lr_sense, monotonic_cst = trend_check(x=X,\n",
    "                                                       y=Y, \n",
    "                                                       sample_weight = S_W)\n",
    "### Бинарный таргет target_type == 'binary'\n",
    "### CART - Decision Tree Classifier \n",
    "        if self.target_type == 'binary':\n",
    "            cart_kwargs = {'min_samples_leaf' : self.min_bin_size,\n",
    "                           'max_leaf_nodes' : self.n_bins,\n",
    "                           'random_state' : self.seed,\n",
    "                           'monotonic_cst': [monotonic_cst],\n",
    "                           'criterion' : 'gini'}    \n",
    "            cart_model = DecisionTreeClassifier(**cart_kwargs)\n",
    "            fit_args = {'X':X,\n",
    "                        'y':Y,\n",
    "                        'sample_weight':S_W}\n",
    "            cart_model.fit(**fit_args)     \n",
    "### Непрерывный таргет target_type == 'continuous'\n",
    "### CART - Decision Tree Regressor\n",
    "        elif self.target_type == 'continuous':\n",
    "            cart_kwargs = {'min_samples_leaf' : self.min_bin_size,\n",
    "                           'max_leaf_nodes' : self.n_bins,\n",
    "                           'random_state' : self.seed,\n",
    "                           'monotonic_cst': [monotonic_cst],\n",
    "#### MAE более устойчив к выбросам, чем MSE, поэтому для качественных признаков выбран MSE, а для количественных MAE\n",
    "                           'criterion' : 'absolute_error'}\n",
    "            cart_model = DecisionTreeRegressor(**cart_kwargs)\n",
    "            fit_args = {'X':X,\n",
    "                        'y':Y,\n",
    "                        'sample_weight':S_W}\n",
    "            cart_model.fit(**fit_args)\n",
    "### Получение split_points\n",
    "        self.split_points = cart_model.tree_.threshold[cart_model.tree_.threshold!=_tree.TREE_UNDEFINED]\n",
    "        self.split_points = np.append(self.split_points, \n",
    "                                      np.inf) # Верхние границы (включительно)\n",
    "        self.split_points.sort()\n",
    "### Построение внутренней таблицы - self.tab для расчета woe\n",
    "#### Основная таблица tab_base       \n",
    "        bin_indexs = pd.cut(self.frame_list[0].values.ravel(),\n",
    "                            bins = np.append(-np.inf, \n",
    "                                             self.split_points),\n",
    "                            include_lowest=True,\n",
    "                            labels=False)+1\n",
    "        data = {feature : self.frame_list[0].values.ravel(), \n",
    "                'bin_index' : bin_indexs, \n",
    "                'target' : self.frame_list[1].values.ravel()} \n",
    "        if self.sample_weight is not None:\n",
    "            data.update({'sample_weight' : self.frame_list[2].values.ravel()})\n",
    "        else:\n",
    "            pass\n",
    "        self.tab_base = pd.DataFrame(data)\n",
    "        del data\n",
    "        self.tab_base['bin_index'] = self.tab_base['bin_index'].astype('Int64')\n",
    "        \n",
    "#### Дополнительные таблицы для tab \n",
    "##### Таблица с пропусками\n",
    "        data = {self.feature:self.frame_list[3].values.ravel(),\n",
    "                'bin_index':'Missing',\n",
    "                'target':self.frame_list[4].values.ravel()}\n",
    "        if self.sample_weight is not None:\n",
    "            data.update({'sample_weight':self.frame_list[5].values.ravel()})\n",
    "        else:\n",
    "            pass\n",
    "        na_tab = pd.DataFrame(data)\n",
    "##### Таблица со специальными значениями\n",
    "        data = {self.feature:self.frame_list[6].values.ravel(),\n",
    "                'bin_index':'Special',\n",
    "                'target':self.frame_list[7].values.ravel()}\n",
    "        if self.sample_weight is not None:\n",
    "            data.update({'sample_weight':self.frame_list[8].values.ravel()})\n",
    "        else:\n",
    "            pass\n",
    "        special_tab = pd.DataFrame(data)\n",
    "        del data\n",
    "#### Создание общей таблицы с дополнительными значениями\n",
    "        self.tab_add = pd.concat([na_tab,\n",
    "                                  special_tab]).reset_index(drop=True)\n",
    "\n",
    "##### Снижение размера выходных pickle-файлов\n",
    "        del na_tab, special_tab\n",
    "\n",
    "#### Индексы для таблицы WoE       \n",
    "        self.indxs = ['Special','Missing']\n",
    "        self.indxs = sorted((set(self.indxs))&\\\n",
    "                            set(list(self.tab_add['bin_index'].unique())), key = self.indxs.index)\n",
    "        self.indxs = list(np.sort(self.tab_base['bin_index'].unique()))+self.indxs\n",
    "#### Итоговая таблица self.tab\n",
    "        self.tab = pd.concat([self.tab_base,\n",
    "                              self.tab_add]).reset_index(drop=True)\n",
    "### Создание объекта splits - словаря полученных в результате автоматического разбиения классов, для трансформации\n",
    "        return self\n",
    "#------------------------------------------------------------------------------------ end(2)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(3)\n",
    "#### Можно сделать через @property, но работает и так\n",
    "    def get_auto_split_points(self):\n",
    "        return self.split_points\n",
    "#------------------------------------------------------------------------------------ end(3)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(4)\n",
    "## Пользовательская (ручная) коррекция полученных границ бинов \n",
    "#### Применяется только к основным данным\n",
    "    def user_split_points(self,\n",
    "                          user_split_points=None):\n",
    "#### user_splits при необходимости коррекции разбиения задается, как array-like объект из верхних границ (n_bins-1) бинов \n",
    "#### user_splits = np.array([604.5, 651.5, 670.5, inf]) ! по возрастанию\n",
    "        if user_split_points is not None:\n",
    "            bin_indexs = pd.cut(self.frame_list[0].values.ravel(),\n",
    "                                bins = np.append(-np.inf, \n",
    "                                                 user_split_points),\n",
    "                                include_lowest=True,\n",
    "                                labels=False)+1\n",
    "            data = {feature : self.frame_list[0].values.ravel(), \n",
    "                    'bin_index' : bin_indexs, \n",
    "                    'target' : self.frame_list[1].values.ravel()}\n",
    "            self.tab_base = pd.DataFrame(data)\n",
    "            self.tab_base['bin_index'] = self.tab_base['bin_index'].astype('Int64')\n",
    "            if self.sample_weight is not None:\n",
    "                data.update({'sample_weight' : self.frame_list[2].values.ravel()})\n",
    "            else:\n",
    "                pass\n",
    "            self.tab_base = pd.DataFrame(data)\n",
    "            self.tab = pd.concat([self.tab_base,\n",
    "                                  self.tab_add]).reset_index(drop=True)\n",
    "        else:\n",
    "            pass\n",
    "        return self\n",
    "#------------------------------------------------------------------------------------ end(4)\n",
    "\n",
    "#------------------------------------------------------------------------------------ start(5)\n",
    "## Расчет WoE, IV и получение итоговых таблиц tab и woe\n",
    "    def calculate_woe(self):\n",
    "        self.woe = pd.DataFrame()\n",
    "### Расчет для бинарных показателей\n",
    "        if self.target_type == 'binary':\n",
    "            if self.sample_weight is not None:\n",
    "                self.woe['bin_size'] = self.tab.groupby('bin_index')['sample_weight'].sum()\n",
    "                self.woe['event'] = self.tab.loc[self.tab['target']==1].groupby('bin_index')['sample_weight'].sum()\n",
    "            else:\n",
    "                self.woe['bin_size'] = self.tab.groupby('bin_index').size()\n",
    "                self.woe['event'] = self.tab.loc[self.tab['target']==1].groupby('bin_index').size() \n",
    "\n",
    "            self.woe['event'] = self.woe['event'].fillna(1e-6) # МЕСТО ВОЗМОЖНОЙ ОШИБКИ\n",
    "            self.woe['non_event'] = self.woe['bin_size'] - self.woe['event']\n",
    "            self.woe['event_rate'] = self.woe['event'] / self.woe['bin_size'] \n",
    "            self.woe['dstr_event'] = self.woe['event'] / sum(self.woe['event'])\n",
    "            self.woe['dstr_non_event'] = self.woe['non_event'] / sum(self.woe['non_event'])\n",
    "            self.woe['WoE'] = np.log(self.woe['dstr_non_event'] / self.woe['dstr_event'])\n",
    "            self.woe['IV'] = sum(abs((self.woe['dstr_non_event'] - self.woe['dstr_event']) * self.woe['WoE']))\n",
    "            self.woe['feature'] = self.feature\n",
    "            self.woe['upper_bound'] = self.tab.groupby('bin_index')[self.feature].max()\n",
    "            self.woe['upper_bound'] = self.woe['upper_bound'].replace(self.woe['upper_bound'].max(), np.inf)\n",
    "            self.woe['trend'] = self.lr_sense\n",
    "            self.woe = self.woe[['feature',\n",
    "                                 'bin_size',\n",
    "                                 'event',\n",
    "                                 'event_rate',\n",
    "                                 'WoE',\n",
    "                                 'IV',\n",
    "                                 'upper_bound',\n",
    "                                 'trend']]\n",
    "            self.woe = self.woe.reindex(self.indxs)\n",
    "### Расчет для непрерывных показателей\n",
    "        elif self.target_type == 'continuous':\n",
    "##### QN - Взвешивание целевой переменной (не уверен надо ли это)\n",
    "            # if self.sample_weight is not None:\n",
    "            #     self.tab['target_weighted']=self.tab['target']*self.tab['sample_weight'] \n",
    "#### 'sum_surrogate'/'mean_surrogate'\n",
    "            if self.woe_calc_method == 'mean_surrogate':\n",
    "### Описание: https://gnpalencia.org/optbinning/tutorials/tutorial_continuous.html\n",
    "                self.woe = pd.DataFrame()\n",
    "                if self.sample_weight is not None:\n",
    "                    self.woe['bin_size'] = self.tab.groupby('bin_index')['sample_weight'].sum()\n",
    "                    self.woe['bin_mean'] = self.tab.groupby('bin_index')['target'].mean()\n",
    "                    # self.woe['bin_mean'] = self.tab.groupby('bin_index')['target_weighted'].mean()\n",
    "                    self.woe['mean_target'] = self.tab['target'].mean()\n",
    "                    # self.woe['mean_target'] = self.tab['target_weighted'].mean()\n",
    "                else:\n",
    "                    self.woe['bin_size'] = self.tab.groupby('bin_index').size()\n",
    "                    self.woe['bin_mean'] = self.tab.groupby('bin_index')['target'].mean()\n",
    "                    self.woe['mean_target'] = self.tab['target'].mean()\n",
    "                self.woe['dstr_obs'] = self.woe['bin_size'] / self.woe['bin_size'].sum()\n",
    "                self.woe['WoE'] = self.woe['bin_mean'] - self.woe['mean_target']\n",
    "                self.woe['IV'] = sum(self.woe['dstr_obs']*abs(self.woe['WoE']))\n",
    "                self.woe['feature'] = self.feature\n",
    "                self.woe['upper_bound'] = self.tab.groupby('bin_index')[self.feature].max()\n",
    "                self.woe['upper_bound'] = self.woe['upper_bound'].replace(self.woe['upper_bound'].max(), np.inf)\n",
    "                self.woe['trend'] = self.lr_sense\n",
    "                self.woe = self.woe[['feature',\n",
    "                                     'bin_size',\n",
    "                                     'bin_mean',\n",
    "                                     'mean_target',\n",
    "                                     'WoE',\n",
    "                                     'IV',\n",
    "                                     'upper_bound',\n",
    "                                     'trend']]\n",
    "                self.woe = self.woe.reindex(self.indxs)\n",
    "            elif self.woe_calc_method == 'sum_surrogate':\n",
    "#### Опсиание: https://www.listendata.com/2019/08/WOE-IV-Continuous-Dependent.html\n",
    "                self.woe = pd.DataFrame()\n",
    "                if self.sample_weight is not None:\n",
    "                    self.woe['bin_size'] = self.tab.groupby('bin_index')['sample_weight'].sum()\n",
    "                    self.woe['target_sum'] = self.tab.groupby('bin_index')['target'].sum()\n",
    "                    # self.woe['target_sum'] = self.tab.groupby('bin_index')['target_weighted'].sum()\n",
    "                else:\n",
    "                    self.woe['bin_size'] = self.tab.groupby('bin_index').size()    \n",
    "                    self.woe['target_sum'] = self.tab.groupby('bin_index')['target'].sum()\n",
    "                self.woe['dstr_obs'] = self.woe['bin_size'] / self.woe['bin_size'].sum()\n",
    "                self.woe['dstr_target'] = self.woe['target_sum'] / self.woe['target_sum'].sum()  \n",
    "                self.woe['WoE'] = np.log(self.woe['dstr_target'] / self.woe['dstr_obs'])\n",
    "                self.woe['IV'] = abs((( self.woe['dstr_target'] - self.woe['dstr_obs']) * self.woe['WoE'])).sum()\n",
    "                self.woe['feature'] = self.feature\n",
    "                self.woe['upper_bound'] = self.tab.groupby('bin_index')[self.feature].max()\n",
    "                self.woe['upper_bound'] = self.woe['upper_bound'].replace(self.woe['upper_bound'].max(), np.inf)\n",
    "                self.woe['trend'] = self.lr_sense\n",
    "                self.woe = self.woe[['feature',\n",
    "                                     'bin_size',\n",
    "                                     'target_sum',\n",
    "                                     'WoE',\n",
    "                                     'IV',\n",
    "                                     'upper_bound',\n",
    "                                     'trend']]\n",
    "                self.woe = self.woe.reindex(self.indxs)\n",
    "            elif self.woe_calc_method is None:\n",
    "                print(\"Задайте параметр woe_calc_method во время инициации функции ('sum_surrogate'/'mean_surrogate')\")\n",
    "        self.woe['WoE'] = np.where(self.woe['event']==1e-6, 0, self.woe['WoE']) # ЕЩЕ ОДНО МЕСТО ВОЗМОЖНОЙ ОШИБКИ\n",
    "        self.woe['WoE'] = np.where(self.woe['event']==0, 0, self.woe['WoE']) # ЕЩЕ ОДНО МЕСТО ВОЗМОЖНОЙ ОШИБКИ\n",
    "##### Снижение размера выходных pickle-файлов\n",
    "        del self.frame_list\n",
    "        del self.tab\n",
    "        del self.tab_base\n",
    "        del self.tab_add\n",
    "        return self\n",
    "## Извлечение таблицы WoE\n",
    "    def get_woe_table(self):\n",
    "        return self.woe\n",
    "## WoE трансформация показателей в исходном DataFrame()\n",
    "    def woe_transform(self,\n",
    "                      df,\n",
    "                      drop_bin_index = False):\n",
    "        # regular_bounds = np.array(self.woe[['upper_bound']].loc[~self.woe.index.isin(['Other',\n",
    "        #                                                                               'Special',\n",
    "        #                                                                               'Missing'])])\n",
    "        # if any (regular_bounds<=0) is True:\n",
    "        #     regular_bounds = np.append(-np.inf,regular_bounds) \n",
    "        # else:\n",
    "        #     regular_bounds = np.append(0,regular_bounds)        \n",
    "        regular_bounds = np.append(-np.inf,\n",
    "                                   np.array(self.woe[['upper_bound']].loc[~self.woe.index.isin(['Other',\n",
    "                                                                                                'Special',\n",
    "                                                                                                'Missing'])]))\n",
    "        \n",
    "        regular_bounds.sort()\n",
    "        df['bin_index_'+self.feature] = pd.cut(df[self.feature].values.ravel(),\n",
    "                                               bins = regular_bounds,\n",
    "                                               include_lowest=True,\n",
    "                                               labels=False)+1\n",
    "        df['bin_index_'+self.feature] = df['bin_index_'+self.feature].astype('Int64').astype('string')\n",
    "        df['bin_index_'+self.feature] = df['bin_index_'+self.feature].fillna('Missing')\n",
    "        df['bin_index_'+self.feature] = np.where(df[self.feature].isin(self.special_list),\n",
    "                                                 'Special', \n",
    "                                                 df['bin_index_'+self.feature])\n",
    "        self.woe.index = self.woe.index.astype('string')\n",
    "        df['WoE_'+self.feature]=df['bin_index_'+self.feature].map((self.woe[['WoE']].T.to_dict('records'))[0])\n",
    "        if drop_bin_index:\n",
    "            df = df.drop(columns = ['bin_index_'+self.feature], errors='ignore')\n",
    "        else:\n",
    "            pass\n",
    "        return df\n",
    "#------------------------------------------------------------------------------------ end(5)\n",
    "#------------------------------------------------------------------------------------ END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c1dac-d914-41c2-a1ac-b9c78e672dcd",
   "metadata": {},
   "source": [
    "# Вводные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0718b-f342-46bf-a3c2-08a2e38a18ca",
   "metadata": {},
   "source": [
    "## Идентификаторы модели и наблюдений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822bb0db-2f7c-4dce-8d87-73b74f1883e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_name = 'PD СКБ '+'ЮЛ СПАРК' #Application/Behavioral + CAR/CONSUMER/MORTGAGE/CARDS\n",
    "\n",
    "ident = ['Название клиента',\n",
    "         'ИНН',\n",
    "         'Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ae8ed-cbdd-4cfe-97da-1e6f721329dd",
   "metadata": {},
   "source": [
    "## Целевая перменная - target, веса наблюдений - sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108cd67-c5ec-4fdb-afb5-aa18d372c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'DEF_WITHIN_1Y'\n",
    "sample_weight = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e65495-b35c-40c0-97cb-0819c7bfd393",
   "metadata": {},
   "source": [
    "## Создание папок для работы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a592a-9b75-4534-8544-18b65d746709",
   "metadata": {},
   "source": [
    "### Корневая папка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392377f-9464-4f28-94e1-6f6d4019addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in = r'C:\\Users\\egorenkors\\Desktop\\IRB_ЮЛ\\PD\\in' #Папка с входящими данными\n",
    "path_out = r'C:\\Users\\egorenkors\\Desktop\\IRB_ЮЛ\\PD\\out' #Папка в которой будет результат работы скрипта\n",
    "\n",
    "tt_in = os.path.join(path_in,'*') # Папка с обучающей выборкой\n",
    "\n",
    "# Создание папки вывода\n",
    "path_out = os.path.join(path_out, f'{reg_name}')\n",
    "directories = [path_out]\n",
    "\n",
    "for dir in directories:\n",
    "    try:\n",
    "        os.makedirs(dir)    \n",
    "        print(\"Directory \" , dir ,  \" Created \")\n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , dir ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8ec51-c713-4a6b-ad4b-f6236de93757",
   "metadata": {},
   "source": [
    "### Вложенные папки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0eafa-7a02-46cb-8ae8-01820fb4e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = [os.path.join(path_out,\n",
    "                            r'WoE_графики'),\n",
    "               os.path.join(path_out,\n",
    "                            r'PSI_графики'),\n",
    "               os.path.join(path_out,\n",
    "                            r'Использованные_данные'),\n",
    "               os.path.join(path_out,\n",
    "                            r'Преобразованные_данные'),              \n",
    "               os.path.join(path_out,\n",
    "                            r'Данные_итог'),      \n",
    "               os.path.join(path_out,\n",
    "                            r'Компоненты_модели_pickle'),\n",
    "               os.path.join(path_out,\n",
    "                            r'Компоненты_модели_pickle\\Биннинг'),\n",
    "               os.path.join(path_out,\n",
    "                            r'Компоненты_модели_pickle\\Компоненты_ядра'),\n",
    "               os.path.join(path_out,\n",
    "                            r'Графики распределений')\n",
    "              ]\n",
    "for dir in directories:\n",
    "    try:\n",
    "        os.makedirs(dir)    \n",
    "        print(\"Directory \" , dir ,  \" Created \")\n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , dir ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f52c1-81d6-4f8e-8a07-680fbfe922c1",
   "metadata": {},
   "source": [
    "# ПЕРВЫЙ ВВОД ДАННЫХ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd87772-f766-4906-b3f5-1cab657d2ea7",
   "metadata": {},
   "source": [
    "## Ввод данных train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42347e84-6246-4043-b2bb-4725f80fa68c",
   "metadata": {},
   "source": [
    "### train and test (tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3f8c1-3fed-47a2-b7f2-d54c03b65e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(tt_in)\n",
    "tt = pd.DataFrame()\n",
    "for f in file_list:\n",
    "    data = pd.read_excel(f)\n",
    "    tt = pd.concat([tt, data])\n",
    "    tt= tt.reset_index(drop = True)\n",
    "    del data\n",
    "\n",
    "f_name = os.path.basename(f)    \n",
    "to_print = f_name+' loaded ' + str(tt.shape[0]) + ' obs'\n",
    "\n",
    "# Сохранение исходника тренировочной выборки\n",
    "save_file = os.path.join(path_out, r'Использованные_данные', f_name)\n",
    "tt.to_csv(save_file, index=False)\n",
    "print(to_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c05b6a-d463-4870-a949-426efd9b48a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T20:44:03.678254Z",
     "iopub.status.busy": "2024-09-16T20:44:03.678254Z",
     "iopub.status.idle": "2024-09-16T20:44:03.748565Z",
     "shell.execute_reply": "2024-09-16T20:44:03.747563Z",
     "shell.execute_reply.started": "2024-09-16T20:44:03.678254Z"
    }
   },
   "source": [
    "### Разделение показателей на категориальные и числовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af155d51-e331-4fbe-ac91-a3b550fe5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = tt.drop(columns=ident+[target,\n",
    "                                      sample_weight], \n",
    "                       errors = 'ignore').columns.to_list()\n",
    "numerical = list(tt[all_feats]._get_numeric_data().columns)\n",
    "dummies = list(tt[numerical].loc[:, tt[numerical].nunique()<=2].columns)\n",
    "not_dummies = [col for col in tt[dummies].columns if 'num' in col]\n",
    "dummies = list(set(dummies)-set(not_dummies))\n",
    "numerical = list(set(numerical)-set(dummies))\n",
    "categorical = list(set(all_feats) - set(numerical))\n",
    "not_cats = [col for col in tt[categorical].columns if 'num' in col]\n",
    "not_cats_2 = [col for col in tt[categorical].columns if 'std' in col]\n",
    "categorical = list(set(categorical) - set(not_cats) - set(not_cats_2))\n",
    "numerical = list(set(all_feats) - set(categorical))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb72469-1a3e-460c-b86a-4650c7f796f6",
   "metadata": {},
   "source": [
    "#### Обзор для внесения правок"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717bfc9-09e1-4afb-b576-739bab3c770f",
   "metadata": {},
   "source": [
    "##### Числовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cfa09-4cdc-4ad0-89a3-9aa414eab1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt[numerical].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fffb5-8ce3-4ec5-bb79-ead50d6c41d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T20:49:42.908158Z",
     "iopub.status.busy": "2024-09-16T20:49:42.908158Z",
     "iopub.status.idle": "2024-09-16T20:49:42.911296Z",
     "shell.execute_reply": "2024-09-16T20:49:42.911296Z",
     "shell.execute_reply.started": "2024-09-16T20:49:42.908158Z"
    }
   },
   "source": [
    "##### Категориальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ca960-ed73-45c3-af0d-461b18160a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt[categorical].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d36812-c5ae-4c70-8793-454ca7049a67",
   "metadata": {},
   "source": [
    "##### Правка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b740c-951d-45e7-b9af-ebc5575ca818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf761c0-23d1-4544-957f-79d731930b7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T13:47:30.174805Z",
     "iopub.status.busy": "2024-09-20T13:47:30.174805Z",
     "iopub.status.idle": "2024-09-20T13:47:30.178507Z",
     "shell.execute_reply": "2024-09-20T13:47:30.178507Z",
     "shell.execute_reply.started": "2024-09-20T13:47:30.174805Z"
    }
   },
   "source": [
    "## Обработка +/- бесонечности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f32ba-5a5f-44d4-b3bd-23f56f9df307",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in numerical:\n",
    "    inf_replacer(tt,\n",
    "                 x,\n",
    "                 n_min_max = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43917fda-8c2f-4895-9dc8-6822ac36ea2e",
   "metadata": {},
   "source": [
    "## Описательные статистики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746a1c5-2712-4154-a90a-9c5b0479064d",
   "metadata": {},
   "source": [
    "### Описательные статистики для количественных показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1dc79-adc0-4ac9-9cbf-b109058efcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_descr = tt[numerical].describe(percentiles=[.05, .25, .5, .75, .95]).transpose().round(3)\n",
    "num_descr['nan, %'] = ((tt[numerical].isna().sum()/tt[numerical].shape[0])).round(3)\n",
    "num_descr = num_descr.drop(['count'], axis=1, errors='ignore')\n",
    "num_descr = num_descr\n",
    "num_descr = num_descr.rename(columns ={'50%':'50%(median)', 'index':'feature'}, errors='ignore')\n",
    "\n",
    "save_file = os.path.join(path_out, 'Desc numerical feats.xlsx')\n",
    "num_descr.to_excel(save_file)\n",
    "# num_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7b433-85d2-4a7a-89b3-1d67675bcab9",
   "metadata": {},
   "source": [
    "### Описательные статистики для качественных показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e8af9-a931-4608-906b-6df59f9052fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_descr = tt[categorical].astype('object').describe(include='object').transpose()\n",
    "cat_descr['nan, %'] = ((tt[categorical].isna().sum()/tt[categorical].shape[0])).round(3)\n",
    "cat_descr = cat_descr.drop(['count','freq'], axis=1, errors='ignore')\n",
    "cat_descr = cat_descr\n",
    "cat_descr = cat_descr.rename(columns ={'top':'mode', 'index':'feature', 'unique':'n_unique'}, errors='ignore')\n",
    "\n",
    "save_file = os.path.join(path_out, 'Desc categorical feats.xlsx')\n",
    "cat_descr.to_excel(save_file)\n",
    "# cat_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87200016-3b6b-41b7-9660-86a9059e7a86",
   "metadata": {},
   "source": [
    "## Первичный контроль качества данных и трансформация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3611b3a-c6a1-4ae3-acec-370eb74e3be6",
   "metadata": {},
   "source": [
    "### Фильтр по высокому количеству пропусков (<90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23381046-e64a-414c-882f-4c5ee1ea4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_na_filter = list(num_descr[num_descr['nan, %']>0.9].index)\n",
    "numerical = list(set(numerical)-set(num_na_filter))\n",
    "cat_na_filter = list(cat_descr[cat_descr['nan, %']>0.9].index)\n",
    "categorical = list(set(categorical) - set(cat_na_filter))\n",
    "\n",
    "na_filter = num_na_filter+cat_na_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf0877-81be-4c60-b09e-ad23b2f86ab8",
   "metadata": {},
   "source": [
    "### Менее 2-х уникальных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801d2f1-007f-485c-8586-f58ed8d7cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique_less_2 = tt[all_feats].columns[tt[all_feats].nunique()<2].to_list()\n",
    "numerical = list(set(numerical)-set(nunique_less_2))\n",
    "categorical = list(set(categorical) - set(nunique_less_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6301ae-0381-4d68-8835-1064f1358f6d",
   "metadata": {},
   "source": [
    "### Показатели с высокой концентраией >95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdd72a-f05d-4fdf-a39b-98c527fe5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_concentrated = []\n",
    "for x in all_feats:\n",
    "    if tt[x].value_counts().max()/tt.shape[0] > 0.95:\n",
    "        high_concentrated = high_concentrated + [x]\n",
    "    else:\n",
    "        pass\n",
    "numerical = list(set(numerical)-set(high_concentrated))\n",
    "categorical = list(set(categorical) - set(high_concentrated))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe03b499-ec45-4131-8b35-1ac2ffa087e1",
   "metadata": {},
   "source": [
    "### Данные для трансформации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd12ede-7a3e-4b8e-af77-233ebf01b5e3",
   "metadata": {},
   "source": [
    "#### train - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53abfc9-643e-45ff-a58f-fdf83bc45d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tt.sample(frac= 0.2, \n",
    "                 random_state=seed)\n",
    "train = tt[~tt.index.isin(test.index)]\n",
    "test = test.reset_index(drop=True)\n",
    "train = train.reset_index(drop=True)\n",
    "del tt\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ebe3b-7a2b-4ba8-bd23-eba145921a05",
   "metadata": {},
   "source": [
    "### Трансформация (WoE-биннинг) показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8029a0-f164-491f-9bb8-f8a967b12f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_failed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae19714-bcae-4c32-854c-8372ad7e8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd4160-007e-4e3a-8a29-44d6d3a76ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore', UserWarning)\n",
    "# warnings.simplefilter('default', UserWarning)\n",
    "np.set_printoptions(suppress=False)\n",
    "np.set_printoptions(formatter={'all':lambda x: str(x)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db844b-0dfa-4408-b105-04fcddff9b38",
   "metadata": {},
   "source": [
    "#### Числовые показатели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b2340-466d-4f06-a48f-140a74cf26cd",
   "metadata": {},
   "source": [
    "##### Автоматический биннинг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddded4-b04f-4b2c-a331-4708e9e73721",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(numerical):\n",
    "    try:\n",
    "        bin_model_file = os.path.join(path_out, r'Компоненты_модели_pickle\\Биннинг','bin_model_'+str(x)+'.sav')\n",
    "        locals()['bin_model_' + str(x)] = pickle.load(open(bin_model_file, 'rb'))\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            locals()['bin_model_' + str(x)] = numerical_binning(target_type = 'binary',\n",
    "                                                            n_bins = 5,\n",
    "                                                            min_bin_size = 0.05,\n",
    "                                                            outlier_detector = 'knn',\n",
    "                                                            seed = seed).fit(df = train,\n",
    "                                                                             feature = x,\n",
    "                                                                             target = target).calculate_woe()\n",
    "            save_file = os.path.join(path_out, r'Компоненты_модели_pickle\\Биннинг','bin_model_'+str(x)+'.sav')\n",
    "            pickle.dump(locals()['bin_model_' + str(x)], \n",
    "                        open(save_file, 'wb'))\n",
    "        except:\n",
    "            binning_failed = binning_failed + [x]\n",
    "            pass\n",
    "    if x in binning_failed:\n",
    "        pass\n",
    "    else:\n",
    "        locals()['woe_' + str(x)] = locals()['bin_model_' + str(x)].get_woe_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aad2e00-0b9a-48cf-a167-74d054058e69",
   "metadata": {},
   "source": [
    "##### Внесение правок"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c56d2-6f36-47e0-9c69-b45ba06ecd1f",
   "metadata": {},
   "source": [
    "###### x..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c46093-3e23-4db8-a101-455a7a190766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do_something like bin_model_feature.user_split_points(...).calculate_woe() ... _.get_woe_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45710aca-d6b0-4d20-849c-65a2e22d141f",
   "metadata": {},
   "source": [
    "#### Категориальные показатели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16524686-d4b3-4f48-b30c-10deb5765ff6",
   "metadata": {},
   "source": [
    "##### Автоматический биннинг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee11c0d-96e7-4c92-9d1f-9a3b3c4c4985",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(categorical):\n",
    "    try:\n",
    "        bin_model_file = os.path.join(path_out, r'Компоненты_модели_pickle','bin_model_'+str(x)+'.sav')\n",
    "        locals()['bin_model_' + str(x)] = pickle.load(open(bin_model_file, 'rb'))\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            locals()['bin_model_' + str(x)] = categorical_binning(target_type = 'binary',\n",
    "                                                                  n_bins = 4,\n",
    "                                                                  min_bin_size = 0.05,\n",
    "                                                                  cat_other_cutoff = 0.01,\n",
    "                                                                  seed = seed).fit(df=train,\n",
    "                                                                                   feature = x,\n",
    "                                                                                   target = target).calculate_woe()\n",
    "            save_file = os.path.join(path_out, r'Компоненты_модели_pickle\\Биннинг','bin_model_'+str(x)+'.sav')\n",
    "            pickle.dump(locals()['bin_model_' + str(x)], \n",
    "                        open(save_file, 'wb'))\n",
    "        except:\n",
    "            binning_failed = binning_failed + [x]\n",
    "            pass\n",
    "    if x in binning_failed:\n",
    "        pass\n",
    "    else:\n",
    "        locals()['woe_' + str(x)] = locals()['bin_model_' + str(x)].get_woe_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4294f091-7f19-4f83-ad98-5b59f627c241",
   "metadata": {},
   "source": [
    "#### Внесение правок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef449f-09f3-4239-8119-940c21c53104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do_something like bin_model_feature.user_splits(user_splits = {1:('a','b','c'), 2:('d','e','f'),...,'Special':('...'),...})\n",
    "# _.calculate_woe() ... _.get_woe_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c76e9b-27d6-47d0-a3b6-09d8c5d8034e",
   "metadata": {},
   "source": [
    "### Итоговые таблицы биннинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a4c40-2975-46d8-b7b2-ff15a4cbeb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = list(set(numerical) - set(binning_failed))\n",
    "categorical = list(set(categorical) - set(binning_failed))\n",
    "adj_feats =  numerical + categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37cabd2-fbb2-4845-88a6-42b2b4180736",
   "metadata": {},
   "source": [
    "#### Биннинг числовых показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cd57f-30d4-450d-97ab-71f433592f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_woe_table_total = pd.DataFrame()\n",
    "for x in numerical:\n",
    "    num_woe_table_total = pd.concat([num_woe_table_total,\n",
    "                                    locals()['woe_' + str(x)].reset_index()], \n",
    "                                    ignore_index = True)\n",
    "save_file = os.path.join(path_out, 'Binning numerical feats.xlsx')\n",
    "num_woe_table_total.to_excel(save_file, \n",
    "                             index=False)\n",
    "\n",
    "# num_woe_table_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f149df-b0fe-4a69-bf15-cc202f2efd08",
   "metadata": {},
   "source": [
    "#### Биннинг категориальных показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f2be17-55f2-46f6-b951-e6a8121a91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_woe_table_total = pd.DataFrame()\n",
    "for x in categorical:\n",
    "    cat_woe_table_total = pd.concat([cat_woe_table_total,\n",
    "                                    locals()['woe_' + str(x)].reset_index()], \n",
    "                                    ignore_index = True)\n",
    "save_file = os.path.join(path_out, 'Binning categorical feats.xlsx')\n",
    "cat_woe_table_total.to_excel(save_file, \n",
    "                             index=False)\n",
    "\n",
    "# cat_woe_table_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65b1ce-243a-4faa-9406-5e004b1afc26",
   "metadata": {},
   "source": [
    "### Результат первичной обработки показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb70ba1-1a60-463c-a770-95b022a21896",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_feats = numerical + categorical\n",
    "\n",
    "adj_res = pd.DataFrame({'Показатели': ['Исходной набор',\n",
    "                                       'Отсеиваемые при проверке доли пропусков (>0.9)', \n",
    "                                       'Отсеиваемые при проверке количества уникальных значений (<2)', \n",
    "                                       'Отсеиваемые при проверке конецентрации наблюдений на значениях (>0.95)',\n",
    "                                       'Отсеиваемые из-за невозможности применения алгоритма трансформации',\n",
    "                                       'Очищенный набор'],\n",
    "                       'Список показателей': [all_feats, \n",
    "                                              na_filter,\n",
    "                                              nunique_less_2,\n",
    "                                              high_concentrated,\n",
    "                                              binning_failed,\n",
    "                                              adj_feats],\n",
    "                       'Кол-во показателей в списке':[len(all_feats),\n",
    "                                                      len(na_filter),\n",
    "                                                      len(nunique_less_2),\n",
    "                                                      len(high_concentrated),\n",
    "                                                      len(binning_failed),\n",
    "                                                      len(adj_feats)]})\n",
    "\n",
    "adj_res = adj_res.set_index('Показатели')\n",
    "save_file = os.path.join(path_out, 'Результаты первичного анализа качества '+f'{reg_name}'+'.xlsx')\n",
    "adj_res.to_excel(save_file)\n",
    "\n",
    "adj_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc58e6-add4-41e4-9fd5-d875ae210f01",
   "metadata": {},
   "source": [
    "# Первый вывод данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d1036-8db2-4ca3-8098-a186ce32fd96",
   "metadata": {},
   "source": [
    "## Трансформация показателей в выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba5e9c-c57c-4099-8035-e2a4784fb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(adj_feats):\n",
    "    train = locals()['bin_model_' + str(x)].woe_transform(df=train)\n",
    "    test = locals()['bin_model_' + str(x)].woe_transform(df=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff76529-0de9-4150-88ac-55cc767c2ac0",
   "metadata": {},
   "source": [
    "#### Обработка пропусков и новых значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db57b6c5-9518-4b3d-9df5-8b859e113baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_feats = list(train.columns[train.columns.str.contains(r'^WoE')])\n",
    "bin_indexs = list(train.columns[train.columns.str.contains(r'^bin_index')])\n",
    "\n",
    "\n",
    "for x in woe_feats:\n",
    "    test[x] = test[x].fillna(0)\n",
    "for x in bin_indexs:\n",
    "    test[x] = test[x].fillna('Missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9c820-4567-455d-8643-62495e9dd7d6",
   "metadata": {},
   "source": [
    "#### Сохранение преобразованных выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020b035-ee0b-400b-8622-f2e7d55dfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cols = list(train.columns[train.columns.str.contains(r'^WoE')])+\\\n",
    "list(train.columns[train.columns.str.contains(r'^bin')])\n",
    "\n",
    "if sample_weight is not None:\n",
    "    cols = ident+[target,sample_weight]+transformed_cols\n",
    "else:\n",
    "    cols = ident+[target]+transformed_cols\n",
    "\n",
    "df_list = ['train',\n",
    "           'test']\n",
    "\n",
    "for f in df_list:\n",
    "    f_name = f+'_transformed'\n",
    "    save_file = os.path.join(path_out, r'Преобразованные_данные',\n",
    "                             f_name+'.csv')\n",
    "    locals()[f][cols].to_csv(save_file, index=False)\n",
    "    del locals()[f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1040f-0f6b-4653-a74f-3ddd62d617eb",
   "metadata": {},
   "source": [
    "# Второй ввод данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7e8aa-24c8-4834-9d37-157be088dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = ['train',\n",
    "           'test']\n",
    "\n",
    "for f in df_list:\n",
    "    f_name = f+'_transformed'\n",
    "    file = os.path.join(path_out+r'\\Преобразованные_данные',f_name+'.csv')\n",
    "    data = pd.read_csv(file, \n",
    "                       low_memory=False)\n",
    "    locals()[f] = pd.DataFrame()\n",
    "    locals()[f] = pd.concat([locals()[f], \n",
    "                             data])\n",
    "    locals()[f] = locals()[f].reset_index(drop=True)\n",
    "    del data\n",
    "\n",
    "woe_feats = list(train.columns[train.columns.str.contains(r'^WoE')])\n",
    "bin_indexs = list(train.columns[train.columns.str.contains(r'^bin_index')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f33d89-7ad0-493d-a176-781b4a2304ee",
   "metadata": {},
   "source": [
    "## Однофакторный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdcc7c-ffde-4c3f-806a-2ec9823cff71",
   "metadata": {},
   "source": [
    "### Information Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58976d-3674-4674-925b-dbe160851385",
   "metadata": {},
   "outputs": [],
   "source": [
    "IVs = pd.DataFrame()\n",
    "for x in adj_feats:\n",
    "    IVs = pd.concat([IVs,\n",
    "                     locals()['woe_' + str(x)][['feature','IV']].reset_index(drop=True).iloc[:1]], \n",
    "                    ignore_index=True).reset_index(drop=True)\n",
    "IVs['IV'] = IVs['IV'].fillna(0)\n",
    "IVs = IVs.set_index('feature').sort_values(by='IV')\n",
    "IVs = IVs.sort_values(by='IV', ascending=False)\n",
    "save_file = os.path.join(path_out, 'IVs '+f'{reg_name}'+'.xlsx')\n",
    "IVs.to_excel(save_file)\n",
    "\n",
    "iv_below_002 = list('WoE_' + x for x in list(IVs.loc[round(IVs['IV'],2) < 0.02].index))\n",
    "iv_above_05 = list('WoE_' + x for x in list(IVs.loc[round(IVs['IV'],2) > 0.5].index))\n",
    "\n",
    "\n",
    "IVs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515083f-6806-4b7e-a2b0-ebd08fb5d86d",
   "metadata": {},
   "source": [
    "### Логическая проверка результатов биннинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e41cc-a70b-4914-8cb7-25be49fc61ca",
   "metadata": {},
   "source": [
    "#### Количественные показатели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ce738-3271-4bc9-a742-0a14e05659bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f6b8f-7b2a-4803-932a-e8a7deda5edc",
   "metadata": {},
   "source": [
    "#### Качественные показатели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84356f69-6512-4457-b508-431dfbf72004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d9436-ee14-4e62-9a91-59ac9414e5d9",
   "metadata": {},
   "source": [
    "#### Итоговый список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2518c61-69a9-4f2e-a184-8776e442b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_check_fail = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff467a-a368-4ac2-a6ff-7b5de9d0006c",
   "metadata": {},
   "source": [
    "### Анализ Gini однофакторных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459de26d-28f5-4f71-b0b5-5bb7c379e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, log_loss, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "estimator = LogisticRegression(solver='liblinear', random_state=seed)\n",
    "\n",
    "y_train = train[target].values.ravel()\n",
    "y_test = test[target].values.ravel()\n",
    "\n",
    "Gini_UA = pd.DataFrame(columns = ['Feature', \n",
    "                                  'Gini train', \n",
    "                                  'Gini test'])\n",
    "\n",
    "for x in woe_feats:\n",
    "    x_train = train[x].values.reshape(-1,1)\n",
    "    x_test = test[x].values.reshape(-1,1)\n",
    "    \n",
    "    model = estimator.fit(x_train, y_train)  \n",
    "  \n",
    "    gini_train = 2*roc_auc_score(y_train, model.predict_proba(x_train)[:,1]) - 1\n",
    "    gini_test = 2*roc_auc_score(y_test, model.predict_proba(x_test)[:,1]) - 1\n",
    "    \n",
    "    new_row = pd.DataFrame([{'Feature': x, \n",
    "                             'Gini train' : gini_train,\n",
    "                             'Gini test' : gini_test}])\n",
    "    Gini_UA = pd.concat([Gini_UA,\n",
    "                         new_row], ignore_index=True)\n",
    "Gini_UA['Gini test-train rel_deviation'] = abs(Gini_UA['Gini test']/Gini_UA['Gini train']-1)\n",
    "Gini_UA = Gini_UA.set_index('Feature')\n",
    "\n",
    "Gini_UA = Gini_UA.sort_values(by='Gini test',\n",
    "                              ascending = False)\n",
    "\n",
    "gini_below_005 = list(Gini_UA.loc[round(Gini_UA['Gini train'],2) < 0.05].index)\n",
    "gini_rel_dev_above_025 = list(Gini_UA.loc[round(Gini_UA['Gini test-train rel_deviation'], 2) >= 0.25].index)\n",
    "\n",
    "save_file = os.path.join(path_out, '1D Gini '+f'{reg_name}'+'.xlsx')\n",
    "Gini_UA.to_excel(save_file)\n",
    "\n",
    "Gini_UA.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce682a-fbfa-4f44-80bf-7a1afb1f1cd9",
   "metadata": {},
   "source": [
    "### PSI (индекс стабильности популяции)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc2784-32b9-48a7-a343-8bacf4e1268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PSI_table = pd.DataFrame(columns = ['Feature', \n",
    "                                    'PSI'])\n",
    "PSI_table_detailed = pd.DataFrame()\n",
    "\n",
    "for x in adj_feats:\n",
    "    x_psi = psi_().fit(dev = train,\n",
    "                       val = test,\n",
    "                       feature = x)\n",
    "    save_file = os.path.join(path_out, \n",
    "                             r'PSI_графики')\n",
    "    x_psi.plot(save = save_file)\n",
    "    new_row = pd.DataFrame([{'Feature': 'WoE_'+x, \n",
    "                             'PSI':x_psi.get_psi()}])\n",
    "    PSI_table = pd.concat([PSI_table,\n",
    "                           new_row], ignore_index=True)\n",
    "    PSI_table_detailed = pd.concat([PSI_table_detailed,\n",
    "                                    x_psi.get_table().reset_index()],\n",
    "                                   ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "PSI_table = PSI_table.set_index('Feature')\n",
    "psi_above_025 = list(PSI_table.loc[round(PSI_table['PSI'], 2) >= 0.25].index)\n",
    "\n",
    "PSI_table = PSI_table.sort_values(by='PSI',\n",
    "                                 ascending = False)\n",
    "\n",
    "save_file = os.path.join(path_out, 'PSI '+f'{reg_name}'+'.xlsx')\n",
    "PSI_table.to_excel(save_file)\n",
    "\n",
    "PSI_table_detailed = PSI_table_detailed.set_index('Feature')\n",
    "save_file = os.path.join(path_out, 'PSI detailed '+f'{reg_name}'+'.xlsx')\n",
    "PSI_table_detailed.to_excel(save_file)\n",
    "\n",
    "# PSI_table.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c57227-b378-49ab-ac3f-c4bb5c40b423",
   "metadata": {},
   "source": [
    "### Spearman r - коэфф. корреляции Спирмена для проверки стабильности (<0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8110437-06f2-4486-a942-a0b208de71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sprmn_stab = pd.DataFrame(columns= ['feature',\n",
    "                                    'Spearman_r_(dev/test)',\n",
    "                                    'clean_Spearman_r_(dev/test)']\n",
    "                         )\n",
    "for x in adj_feats:\n",
    "    try:\n",
    "        part = spearmanr_stability(dev = train,\n",
    "                                   val = test,\n",
    "                                   feature = x,\n",
    "                                   target = target)\n",
    "        part['feature'] = x\n",
    "        sprmn_stab = pd.concat([sprmn_stab,\n",
    "                                part], ignore_index=True)\n",
    "    except ValueError:\n",
    "        part['feature'] = x\n",
    "        part['Spearman_r_(dev/test)'] = np.nan\n",
    "        part['clean_Spearman_r_(dev/test)'] = np.nan\n",
    "        sprmn_stab = pd.concat([sprmn_stab,\n",
    "                                part], ignore_index=True)\n",
    "\n",
    "sprmn_stab = sprmn_stab.fillna(0)\n",
    "sprmn_stab = sprmn_stab.set_index('feature')\n",
    "\n",
    "sprmn_stab = sprmn_stab.sort_values(by='clean_Spearman_r_(dev/test)')\n",
    "\n",
    "save_file = os.path.join(path_out, 'Spearman_R '+f'{reg_name}'+'.xlsx')\n",
    "sprmn_stab.to_excel(save_file)\n",
    "\n",
    "sprmnr_below_03 = list(sprmn_stab.loc[round(sprmn_stab['Spearman_r_(dev/test)'],2) < 0.3].index)\n",
    "\n",
    "# sprmn_stab.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f317d7af-83d4-4568-9e2e-97fac51d36ab",
   "metadata": {},
   "source": [
    "### Результат однофакторного анализа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64cbbb-6597-4e54-8393-437fa77af933",
   "metadata": {},
   "source": [
    "#### Решение о (не-)применении критериев фильтрации однофакторного анализа ('y'/'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f99c5d-fc40-4995-bb0d-869580818655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтр по IV \"снизу\"\n",
    "iv_low_filter = 'y' \n",
    "\n",
    "# Фильтр по IV \"сверху\"\n",
    "iv_top_filter = 'n'\n",
    "\n",
    "# Фильтр по Gini \"снизу\"\n",
    "gini_low_filter = 'y'\n",
    "\n",
    "# Фильтр по изменение Gini в test\n",
    "gini_dev_filter = 'n'\n",
    "\n",
    "# Фильтр по логической непротиворечивости\n",
    "logical_filter = 'n'\n",
    "\n",
    "# Фильтр по PSI (стабильность)\n",
    "psi_filter = 'n'\n",
    "\n",
    "# Фильтр по Spearman R (стабильность)\n",
    "spearman_r_filter = 'n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b370edf-6a0a-4da0-b73c-99df1a065e0c",
   "metadata": {},
   "source": [
    "#### Таблица с результатами 1D анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5f6f0-0cc4-4860-8b25-4bd1d84e918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_adj = woe_feats.copy()\n",
    "\n",
    "## IV\n",
    "### Фильтр - IV ниже 0.02\n",
    "if iv_low_filter == 'y':\n",
    "    woe_adj = list(set(woe_adj)-set(iv_below_002))\n",
    "else:\n",
    "    pass\n",
    "### Фильтр - IV выше 0.5\n",
    "if iv_top_filter == 'y':\n",
    "    woe_adj = list(set(woe_adj)-set(iv_above_05))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "## Gini\n",
    "### Фильтр - Gini ниже 0.05\n",
    "if gini_low_filter == 'y':\n",
    "    woe_adj = list(set(woe_adj)-set(gini_below_005))\n",
    "else:\n",
    "    pass\n",
    "### Фильтр - Относительное изменение Gini >25%\n",
    "if gini_dev_filter == 'y':\n",
    "    woe_adj = list(set(woe_adj)-set(gini_rel_dev_above_025))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "## PSI\n",
    "### PSI выше 0.25\n",
    "if psi_filter == 'y':\n",
    "    woe_adj = list(set(woe_adj)-set(psi_above_025))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "## Spearman_r\n",
    "### Spearman_r < 0.3\n",
    "if spearman_r_filter == 'y':\n",
    "    woe_adj = list(set(woe_adj)-set(sprmnr_below_03))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "## Бизнес-логика\n",
    "### Фильтр - соотвествие показателя бизнес-логике\n",
    "if logical_filter == 'y':\n",
    "    woe_adj = list(set(woe_adj)-set(logical_check_fail))\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "adj_res = pd.DataFrame({'Показатели': ['Исходной набор',\n",
    "                                       'Отсеиваемые при проверке значений IV (<0.02)', \n",
    "                                       'Отсеиваемые при проверке значений IV (>0.5)', \n",
    "                                       'Отсеиваемые при проверке значений Gini (<0.05)',\n",
    "                                       'Отсеиваемые при проверки стабильности Gini (rel_dev<0.25)',\n",
    "                                       'Отсеиваемые при проверке значений PSI (>0.25)',\n",
    "                                       'Отсеиваемые при проверке значений SpearmanR (<0.3)',\n",
    "                                       'Отсеиваемые при логической проверке', \n",
    "                                       'Очищенный набор'],\n",
    "                       'Список показателей': [woe_feats, \n",
    "                                              iv_below_002,\n",
    "                                              iv_above_05,\n",
    "                                              gini_below_005,\n",
    "                                              gini_rel_dev_above_025, \n",
    "                                              psi_above_025,\n",
    "                                              sprmnr_below_03,\n",
    "                                              logical_check_fail,\n",
    "                                              woe_adj],\n",
    "                       'Кол-во показателей в списке':[len(woe_feats),\n",
    "                                                      len(iv_below_002),\n",
    "                                                      len(iv_above_05),\n",
    "                                                      len(gini_below_005),\n",
    "                                                      len(gini_rel_dev_above_025),\n",
    "                                                      len(psi_above_025),\n",
    "                                                      len(sprmnr_below_03),\n",
    "                                                      len(logical_check_fail),\n",
    "                                                      len(woe_adj)],\n",
    "                       'Использование фильтра y/n':['-',\n",
    "                                                    iv_low_filter,\n",
    "                                                    iv_top_filter,\n",
    "                                                    gini_low_filter,\n",
    "                                                    gini_dev_filter,\n",
    "                                                    psi_filter,\n",
    "                                                    spearman_r_filter,\n",
    "                                                    logical_filter,\n",
    "                                                   '-']})\n",
    "\n",
    "adj_res = adj_res.set_index('Показатели')\n",
    "save_file = os.path.join(path_out, 'Результаты 1D анализа '+f'{reg_name}'+'.xlsx')\n",
    "adj_res.to_excel(save_file)\n",
    "\n",
    "adj_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951a037-b634-402c-b998-946213483829",
   "metadata": {},
   "source": [
    "# Второй вывод данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413df9f-e3cc-4beb-8dec-f78d519b6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_weight is not None:\n",
    "    cols = ident+[target,sample_weight]+woe_adj\n",
    "else:\n",
    "    cols = ident+[target]+woe_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec7424-e80a-43f0-b1e1-bfcb3b0622bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = ['train',\n",
    "           'test']\n",
    "\n",
    "for f in df_list:\n",
    "    f_name = f+'_transformed_adjusted'\n",
    "    save_file = os.path.join(path_out, r'Преобразованные_данные',\n",
    "                             f_name+'.csv')\n",
    "    locals()[f][cols].to_csv(save_file, index=False)\n",
    "    del locals()[f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6498bd-e45d-4973-a3db-33afb5c8d507",
   "metadata": {},
   "source": [
    "# Третий ввод данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1ab21-045c-44ff-94bf-68622cb71376",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', \n",
    "                      category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ee39d-c1fe-48a6-9998-f30013489422",
   "metadata": {},
   "source": [
    "#### Выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e0d6ba-3282-4814-9161-129dffcf50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = ['train',\n",
    "           'test']\n",
    "\n",
    "for f in df_list:\n",
    "    f_name = f+'_transformed_adjusted'\n",
    "    file = os.path.join(path_out+r'\\Преобразованные_данные',f_name+'.csv')\n",
    "    data = pd.read_csv(file, \n",
    "                       low_memory=False)\n",
    "    locals()[f] = pd.DataFrame()\n",
    "    locals()[f] = pd.concat([locals()[f], \n",
    "                             data])\n",
    "    locals()[f] = locals()[f].reset_index(drop=True)\n",
    "    del data\n",
    "\n",
    "woe_feats = list(train.columns[train.columns.str.contains(r'^WoE')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268685f3-44bc-4e98-a7d1-34db342f50a2",
   "metadata": {},
   "source": [
    "## Многофакторный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec81451-711d-4d3e-9bb7-f2ffcfb9ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    overfitting_feats\n",
    "except NameError:\n",
    "    overfitting_feats = []\n",
    "else:\n",
    "    print(overfitting_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99abdb76-ac52-4fa6-ad74-80892d1780a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    high_vif_feats\n",
    "except NameError:\n",
    "    high_vif_feats = []\n",
    "else:\n",
    "    print(high_vif_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f93a7-d8dc-418f-80df-30bab827ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_feats = list(set(woe_feats)-set(overfitting_feats)-set(high_vif_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450d75be-a9ce-43d4-b625-2cb2aa3f52b8",
   "metadata": {},
   "source": [
    "## Отбор показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b7595f-ed35-411c-b36f-fd7aca977ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a8b16-f190-4e83-9e56-6b2bd9703445",
   "metadata": {},
   "source": [
    "### Параметры модели (Логит)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77adee-6d8a-4b39-99ce-8d95b8ad41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# penalty 'L1', 'l2', 'elasticnet'\n",
    "# elacticnet = l1&l2\n",
    "\n",
    "estimator = LogisticRegression(solver='saga',\n",
    "                               max_iter=100,\n",
    "                               penalty = 'elasticnet',\n",
    "                               C=1.0, \n",
    "                               fit_intercept=True,\n",
    "                               random_state = seed,\n",
    "                               n_jobs = -1,\n",
    "                               l1_ratio=0.5)\n",
    "\n",
    "# Не вижу смысла в подборе гипер-параметров, т.к. это оказывает минимальное влияние на линейные регрессионные модели\n",
    "# Попробовать по-экспериментировать с l2 и elasticnet и мультиколлениарностью "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99ee37-9224-45c2-9fa1-e91eeaca4c2b",
   "metadata": {},
   "source": [
    "### Отбор показателей (mlxtend SFFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654edca7-a937-4fd1-98cd-76668807e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поробовать backawrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18e7f0-aba9-4556-9f45-53560d0917e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cffe4f-3a47-40ed-87a0-f98c15d53e34",
   "metadata": {},
   "source": [
    "#### Алгоритм SFS (сейчас floating forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae1be0-c987-4505-b368-74d515b9fc06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, \n",
    "                     shuffle = True, \n",
    "                     random_state=seed)\n",
    "\n",
    "# По умолчанию выбирает 10 лучших, финальный размер набора показателей определяется на усмотрение моделиста\n",
    "sfs = SFS(estimator = estimator, \n",
    "          k_features=10, \n",
    "          forward=True, \n",
    "          floating=True, \n",
    "          verbose = 10,\n",
    "          scoring='roc_auc',\n",
    "          n_jobs = 1,\n",
    "          cv=cv)\n",
    "\n",
    "sfs = sfs.fit(X = train[woe_feats],\n",
    "              y = train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3d8acf-cfea-4ac3-b9c7-3d3f57ce8400",
   "metadata": {},
   "source": [
    "#### Таблица результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4b133-9855-4c7c-b857-ad481b04fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_sfs = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "table_sfs = table_sfs.drop(['cv_scores', 'feature_idx'], axis = 1)\n",
    "table_sfs = table_sfs.rename(columns={'feature_names':'selected features','avg_score': 'avg_auc_roc'})\n",
    "\n",
    "table_sfs['avg_auc_roc increase']=np.nan\n",
    "for n in list(range(2, table_sfs.shape[0])):\n",
    "    table_sfs['avg_auc_roc increase'][n]=(table_sfs['avg_auc_roc'][n]-table_sfs['avg_auc_roc'][n-1]).round(3)\n",
    "table_sfs['avg_auc_roc increase']=np.where(table_sfs['avg_auc_roc increase'].isna(), \n",
    "                                        table_sfs['avg_auc_roc'], \n",
    "                                        table_sfs['avg_auc_roc increase'])\n",
    "\n",
    "table_sfs = table_sfs[['selected features',\n",
    "                    'avg_auc_roc', \n",
    "                    'avg_auc_roc increase', \n",
    "                    'ci_bound', \n",
    "                    'std_dev',\n",
    "                    'std_err']]\n",
    "table_sfs.index = table_sfs.index.rename('features n')\n",
    "\n",
    "save_file = os.path.join(path_out, 'SFS (выбор показателей) '+f'{reg_name}'+'.xlsx')\n",
    "table_sfs.to_excel(save_file)\n",
    "\n",
    "table_sfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565da0c-4701-4a21-8064-b24934b880ee",
   "metadata": {},
   "source": [
    "#### Указать число включаемых в модель показателей n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76e10e-ee51-4f9e-81cc-e5bdefe178f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 7\n",
    "\n",
    "best_feats = list(table_sfs['selected features'][n_features])\n",
    "best_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349226b-88b0-4d08-ae29-5781a3d3b681",
   "metadata": {},
   "source": [
    "### Тест на переобученность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31aa33-5321-4a6f-a4c5-b547720d5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[best_feats]\n",
    "y_train = train[target]\n",
    "\n",
    "x_test = test[best_feats]\n",
    "y_test = test[target]\n",
    "\n",
    "\n",
    "#Обучение модели\n",
    "model = estimator.fit(x_train, \n",
    "                      y_train)\n",
    "\n",
    "over_test_table = pd.DataFrame(columns = ['Gini train', \n",
    "                               'Gini test', \n",
    "                               'Исключаемый фактор',\n",
    "                               'Падение Gini на обучающей выборке',\n",
    "                               'Падение Gini на тестовой выборке',\n",
    "                               'overfitting'])\n",
    "\n",
    "gini_test = 2*roc_auc_score(y_test, model.predict_proba(x_test)[:,1]) - 1\n",
    "gini_train = 2*roc_auc_score(y_train, model.predict_proba(x_train)[:,1]) - 1\n",
    "\n",
    "new_row = {'Gini train':gini_train,\n",
    "           'Gini test':gini_test,\n",
    "           'Исключаемый фактор': 'Все включены'}\n",
    "over_test_table = pd.concat([over_test_table, pd.DataFrame([new_row])],ignore_index=True)\n",
    "\n",
    "for x in best_feats:\n",
    "    x_subset = best_feats.copy()\n",
    "    x_subset.remove(x)    \n",
    "    x_train_1 = train[x_subset]\n",
    "    y_train_1 = train[target]\n",
    "    x_test_1 = test[x_subset]\n",
    "    y_test_1 = test[target]\n",
    "    m_test = estimator.fit(x_train_1,  y_train_1)\n",
    "  \n",
    "    gini_test = 2*roc_auc_score(y_test_1, \n",
    "                                m_test.predict_proba(x_test_1)[:,1]) - 1\n",
    "    \n",
    "    gini_train = 2*roc_auc_score(y_train_1, \n",
    "                                 m_test.predict_proba(x_train_1)[:,1]) - 1\n",
    "    new_row = {'Gini train':gini_train.round(3),'Gini test':gini_test.round(3), 'Исключаемый фактор': x}\n",
    "    over_test_table = pd.concat([over_test_table, pd.DataFrame([new_row])],ignore_index=True)\n",
    "\n",
    "rows = list(range(1, over_test_table.shape[0]))\n",
    "for n in rows:\n",
    "    over_test_table['Падение Gini на обучающей выборке'][n] = over_test_table['Gini train'][0]-over_test_table['Gini train'][n]\n",
    "    over_test_table['Падение Gini на тестовой выборке'][n] = over_test_table['Gini test'][0]-over_test_table['Gini test'][n]\n",
    "    over_test_table['overfitting'][n] = np.where((over_test_table['Падение Gini на обучающей выборке'][n]>0.1), 1, 0)\n",
    "over_test_table = over_test_table.set_index('Исключаемый фактор')\n",
    "\n",
    "\n",
    "save_file = os.path.join(path_out, 'overfitting  test'+f'{reg_name}'+'.xlsx')\n",
    "over_test_table.to_excel(save_file)    \n",
    "over_test_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739556e-40e6-487c-9d0a-268a665877a2",
   "metadata": {},
   "source": [
    "#### Список показателей на которые модель переобучается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc5c0c-7d2f-4b2b-9ac0-8559324f41f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitting_feats = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820712b1-7409-4cb4-9d7c-c0e8b7db4ed1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Проверка стат.-значимости переменных (p-значения)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5a5e7-b263-4b61-92f4-1a17c6c8f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estimator.fit(x_train,\n",
    "                      y_train)\n",
    "params = np.append(model.intercept_,model.coef_)\n",
    "predictions = model.predict(x_train)\n",
    "newX = pd.DataFrame({'Constant':np.ones(len(x_train))}).join(pd.DataFrame(x_train))\n",
    "MSE = (sum((y_train-predictions)**2))/(len(newX)-len(newX.columns))\n",
    "var_b = MSE*(np.linalg.inv(np.dot(newX.T,newX)).diagonal())\n",
    "sd_b = np.sqrt(var_b)\n",
    "ts_b = params/sd_b\n",
    "p_values =[2*(1-stats.t.cdf(np.abs(i),(len(newX)-len(newX.columns)))) for i in ts_b]\n",
    "sd_b = np.round(sd_b,9)\n",
    "ts_b = np.round(ts_b,9)\n",
    "p_values = np.round(p_values,9)\n",
    "params = np.round(params,9)\n",
    "coeffs = pd.DataFrame()\n",
    "coeffs['Coefficient'],coeffs['Std. err'],coeffs['p-values'] = [params,sd_b,p_values]\n",
    "coeffs['Feature']=['intercept']+list(model.feature_names_in_)\n",
    "coeffs = coeffs.set_index('Feature')\n",
    "save_file = os.path.join(path_out, 'Модель '+f'{reg_name}'+'.xlsx')\n",
    "coeffs.to_excel(save_file)\n",
    "gc.collect()\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c27ad-17a0-4f8c-9e96-7e0f14ad6d97",
   "metadata": {},
   "source": [
    "#### Список незначимых показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f567aeed-a6c2-4fa3-8960-62a520a97e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_p_value_feats = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb98dd03-944f-4709-938c-940f2e57ab16",
   "metadata": {},
   "source": [
    "### Variance inflation factor (VIF) для проверки мультиколлинеарности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a0e4a-301f-4674-94ed-eaeb71125c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ffbbca-f7f6-49eb-ac2f-fc9d695944c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если значение больше 5 тогда следует исключить фактор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a971f63-4b8e-4319-bc25-e123b25ca41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[best_feats]\n",
    "X['intercept'] = coeffs['Coefficient'][0]\n",
    "X = X[['intercept']+best_feats]\n",
    "VIF = pd.DataFrame()\n",
    "VIF['VIF'] = [variance_inflation_factor(X.values, i) \n",
    "              for i in range(X.shape[1])]\n",
    "VIF['Feature'] = X.columns \n",
    "VIF = VIF.set_index('Feature')\n",
    "save_file = os.path.join(path_out, 'VIF test' + f' {reg_name}'+'.xlsx')\n",
    "VIF.to_excel(save_file)\n",
    "VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4874e-eb8a-4c99-b902-307db29a8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_vif_feats = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801f85b-3a44-48f8-ba96-38531cf80751",
   "metadata": {},
   "source": [
    "## Метрики качества полученной модели и их визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c737a3a5-d5da-485f-993b-bdf75d6a0fc9",
   "metadata": {},
   "source": [
    "### ROC-кривая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c08e25-2d06-492e-bda7-02b271d845be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddbf15-ead0-4d5f-96a8-af260c542280",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[best_feats]\n",
    "y_train = train[target].values\n",
    "\n",
    "x_test = test[best_feats]\n",
    "y_test = test[target].values\n",
    "\n",
    "model = estimator.fit(x_train, \n",
    "                      y_train)\n",
    "\n",
    "# График ROC\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "probas_train = model.predict_proba(x_train) # еще раз расчет вероятностей\n",
    "fpr, tpr, thresholds = roc_curve(y_train, probas_train[:, 1])\n",
    "roc_auc  = auc(fpr, tpr) # формула расчета ROC\n",
    "pl.plot(fpr, tpr, label='%s AUC = %0.2f'  % ('train:',roc_auc) +';' + '%s Gini = %0.2f ' % ('', round(2*roc_auc_score(y_train, model.predict_proba(x_train)[:,1]) - 1, 3))) \n",
    "pl.plot([0, 1], [0, 1], 'k--')\n",
    "pl.legend(loc=0)\n",
    "\n",
    "probas_test = model.predict_proba(x_test) # еще раз расчет вероятностей\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_test[:, 1])\n",
    "roc_auc  = auc(fpr, tpr) # формула расчета ROC\n",
    "pl.plot(fpr, tpr, label='%s AUC = %0.2f'  % ('test:',roc_auc) +';' + '%s Gini = %0.2f ' % ('', round(2*roc_auc_score(y_test, model.predict_proba(x_test)[:,1]) - 1, 3)))\n",
    "pl.plot([0, 1], [0, 1], 'k--')\n",
    "pl.legend(loc=0)\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "NAME = 'Logit '+f'{reg_name}'\n",
    "plt.title(NAME)\n",
    "save_file = os.path.join(path_out, 'ROC_curve '+f'{reg_name}'+'.png')\n",
    "plt.savefig(save_file, \n",
    "            bbox_inches='tight', \n",
    "            pad_inches=0.05, \n",
    "            dpi=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8507b6-9b52-4d92-b380-2d7c923c6f41",
   "metadata": {},
   "source": [
    "# Выгрузка pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4391c1-67b1-4eca-b673-4dd0be8d75a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T01:11:56.260502Z",
     "iopub.status.busy": "2024-10-01T01:11:56.260502Z",
     "iopub.status.idle": "2024-10-01T01:11:56.264382Z",
     "shell.execute_reply": "2024-10-01T01:11:56.264382Z",
     "shell.execute_reply.started": "2024-10-01T01:11:56.260502Z"
    }
   },
   "source": [
    "### Модель logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24293940-e642-4f67-a4fc-91bce24c5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = os.path.join(path_out, \n",
    "                         r'Компоненты_модели_pickle\\Компоненты_ядра','Model '+f'{reg_name}'+'.sav')\n",
    "pickle.dump(model, \n",
    "            open(save_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a4e3f-2b18-4d07-99b0-5b5e879cbd74",
   "metadata": {},
   "source": [
    "### Биннинг показателей в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63749ddb-1f4c-4650-ac9a-0e2a3c8a0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in best_feats:\n",
    "    feat = str(x).replace('WoE_', '') \n",
    "    save_file = os.path.join(path_out, \n",
    "                         r'Компоненты_модели_pickle\\Компоненты_ядра','bin_model_'+f'{feat}'+'.sav')\n",
    "    pickle.dump(locals()['bin_model_' + str(feat)], \n",
    "                open(save_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de954893-f79e-4b88-ab16-542b64b908ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d11109-cb03-422e-bc22-fcacab49a577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b37e08c-bead-4b5b-bebd-7ff3c83d8ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
